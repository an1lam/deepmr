Deep learning models have achieved success predicting many genomic features such as transcription factor (TF) binding \citep{alipanahi2015predicting, zhou2015predicting}, chromatin accessibility \citep{zhou2015predicting, kelley2016basset}, histone marks \citep{yin2019deephistone}, and RNA binding protein (RBP) binding \citep{alipanahi2015predicting, pan2017rna, gandhi2018cdeepbind, zheng2018deep} from genomic sequence. These models achieve high predictive accuracy and recognize sequence features that match those found by orthogonal experiments. In particular, multi-task models such as DeepSEA~\citep{zhou2015predicting} and BPNet~\citep{avsec2020base} can accurately predict multiple genomic features simultaneously. Do such multi-task models, through learning to predict multiple features jointly, gain an implicit understanding of mechanistic, causal relationships between features?

We attempt to answer this question by developing Deep Mendelian Randomization (\method), a method that can identify causal relationships in the presence of potential unobserved confounding. \method\ combines \textit{in silico} mutagenesis with Mendelian randomization \citep{lawlor2008mendelian}, an instrumental variable approach for causal inference, to estimate learned causal effects in genomic deep learning models. \method\ obtains local (sequence level) and global (genome level) estimates of (an assumed) linear causal relationship between pairs of features learned by a multi-task genomic prediction model.

We tested \method\ in three experiments. In the first experiment, we simulated data based on a model of directional cooperativity between TFs and tested whether \method\ could recover the causal relationship between the two TFs. \method\ gave good estimates of the `true' global causal effect but didn't perform as well at estimating sequence-region level causal effects. Therefore, in the second and third experiments, we used \method\ to examine what global relationships between features two published models, BPNet~\citep{avsec2020base} and DeepSEA~\citep{zhou2015predicting}, learn. In the BPNet experiment, \method\ reproduced the paper's finding that 2 of the 4 TFs modeled strongly influence each others' and the two other TFs' binding but not the reverse. In the DeepSEA experiment, \method\ \dots

\subsection{Related Work}
Our work draws on four threads of work spanning machine learning and statistical genetics.

\subsubsection{Deep Learning for Functional Genomics}%
Functional genomics research maps sequence-to-function relationships between genotype and molecular phenotypes by leveraging large-scale observational data from high-throughput assays such as ChIP-seq, DNase-seq, and ATAC-seq. Understanding this mapping enables better understanding of epigenomic regulation and more accurate prediction of downstream traits. However, achieving this goal requires decoding complex relationships between high-dimensional genomic sequence inputs and interrelated outputs from large, noisy datasets. Encouraged by deep learning models' ability to overcome similar challenges in the fields of computer vision and natural language processing, genomics researchers have trained deep learning models on functional genomics datasets with moderate success. 

Early work on deep learning for functional genomics proved that deep learning models could predict sequence-to-function relationships accurately and showed their promise for identifying trait-associated variants. DeepBind \citep{alipanahi2015predicting}, one of the earliest deep learning sequence-to-function classification models, outperformed then state-of-the-art models at predicting TF binding and RBP binding from sequence. DeepBind and other classification models -- e.g. DeepSEA~\citep{zhou2015predicting} and Basset~\citep{kelley2016basset} -- also performed well at classifying and annotating trait-associated variants using their own predictions, identifying variants with higher accuracy than existing methods. More recent work has applied deep learning models to deepening understanding by decoding epigenomic regulatory logic. \cite{avsec2020base} trained a regression model, BPNet, to predict 4 TFs and used it to dissect the motif-based regulatory logic that governs the binding of these TFs. Together, these papers illustrate the promise of deep learning models for not only predicting function from sequence but also improving our understanding of epigenomic regulation and ability to anticipate disease risk. In our work, we seek evidence that genomic deep learning models learn the high-level relationships between features we expect them to, thereby increasing confidence in their capabilities. 

\subsubsection{Model Interpretability}%
\label{ssub:model_interpretability}
Local interpretation methods characterize how specific input (sequence) features influence predictions and in some cases, intermediate layer activations (e.g., saliency maps \citep{simonyan2013deep}, guided back-propagation \citep{springenberg2014striving}, DeepLIFT \citep{shrikumar2017learning}, and DeepSHAP \citep{lundberg2017unified}). Even DeepLIFT, which was designed with genomic deep learning in mind, focuses on interpreting individual model predictions for a single output rather than discovering relationships between outputs and is therefore complementary to our work.

Saturation \emph{in silico} mutagenesis characterizes how a model's predictions for an input change as a result of all possible point mutations to the input. Saturation mutagenesis has been used to assess the learned representations of genomic deep learning models such as DeepBind \citep{alipanahi2015predicting}, cDeepBind \citep{gandhi2018cdeepbind}, DeepSEA \citep{zhou2015predicting}, and Basset \citep{kelley2016basset}. Here, we use saturation mutagenesis (combined with MC-dropout \citep{gal2016dropout}, see Section \ref{sec:dl_uncertainty}) to generate a set of estimated variant \textit{effect sizes} which we then provide as input to Mendelian randomization.

\subsubsection{Uncertainty Estimates and Calibration of Deep Learning Models}

\subsubsection{Mendelian Randomization}
Mendelian randomization (MR) is a technique for estimating linear causal effects in the presence of potential unobserved confounders. MR is an instrumental variable method where the instrument(s) are genetic variants. While MR is typically used to estimate inter-phenotype causal effects from population-scale observational data (i.e., genome-wide association studies, GWAS), here we explore its application to estimating causal effects implied by model-generated data.

\paragraph{Mendelian Randomization Assumptions}
\label{par:rel_work_mr_assumptions}
MR only produces valid causal effect estimates under the following assumptions (Figure \ref{fig:model_overview} under \underline{Estimate}) \cite{lawlor2008mendelian}. Let $ Z $ be a variable we intend to use as an instrument (a genetic variant for example), $ X $ a purported cause (\textit{exposure}), and $ Y $ a purported effect (\textit{outcome}), and suppose that there may be unobserved confounding between $ X $ and $ Y $, denoted by $ U $. Then, MR gives an unbiased estimate of the causal effect of $X$ on $Y$ if:
\begin{enumerate}
    \item \textbf{Unconfoundedness}: $ Z $ is independent of $ U $, \label{item:mr_ass_1}
    \item $ Z $ is not independent of $ X $,  and \label{item:mr_ass_2}
    \item \textbf{Exclusion Restriction}: $ Z $ only influences $ Y $ through $ X $. \label{item:mr_ass_3}
\end{enumerate}

Recently developed MR methods such as Robust Adjusted Profile Score \cite{zhao2018statistical}, MR-Egger \cite{bowden2015mendelian}, and the modal-based estimator \cite{burgess2018modal} leverage multiple instruments to relax some of these assumptions without compromising the validity of results. In this work, we estimate causal effects using a robust variant of MR-Egger with the goal of being robust to invalid instruments.
