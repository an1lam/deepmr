{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRuPISG391E3"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "u_5mSHbhNCVk",
    "outputId": "4aafeefc-1d31-4a75-9c3a-284ff5ba5a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HDF5_USE_FILE_LOCKING=FALSE\n"
     ]
    }
   ],
   "source": [
    "%env HDF5_USE_FILE_LOCKING=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "75gZh6kYpZ01",
    "outputId": "683594b8-3633-4622-a26c-aae5c1699525"
   },
   "outputs": [],
   "source": [
    "import bpnet\n",
    "from bpnet.cli.contrib import ContribFile\n",
    "from bpnet.plot.tracks import plot_tracks, to_neg\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, HTML\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUMU-vxK7Qqr"
   },
   "source": [
    "#### Optional: Setup wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pay9JFgR3YNi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/an1lam/bpnet-training\" target=\"_blank\">https://app.wandb.ai/an1lam/bpnet-training</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/an1lam/bpnet-training/runs/lmpui8st\" target=\"_blank\">https://app.wandb.ai/an1lam/bpnet-training/runs/lmpui8st</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-31 20:32:44,693 [INFO] file/dir created: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/wandb-metadata.json\n",
      "2020-08-31 20:32:44,750 [INFO] system metrics and metadata threads started\n",
      "2020-08-31 20:32:44,751 [INFO] checking resume status, waiting at most 10 seconds\n",
      "2020-08-31 20:32:44,865 [INFO] resuming run from id: UnVuOnYxOmxtcHVpOHN0OmJwbmV0LXRyYWluaW5nOmFuMWxhbQ==\n",
      "2020-08-31 20:32:44,871 [INFO] upserting run before process can begin, waiting at most 10 seconds\n",
      "2020-08-31 20:32:44,963 [INFO] saving pip packages\n",
      "2020-08-31 20:32:44,965 [INFO] initializing streaming files api\n",
      "2020-08-31 20:32:44,969 [INFO] unblocking file change observer, beginning sync with W&B servers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/an1lam/bpnet-training/runs/lmpui8st"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-31 20:32:44,979 [INFO] shutting down system stats and metadata service\n",
      "2020-08-31 20:32:45,692 [INFO] file/dir modified: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/config.yaml\n",
      "2020-08-31 20:32:45,752 [INFO] stopping streaming files and file change observer\n",
      "2020-08-31 20:32:45,801 [INFO] file/dir created: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/wandb-summary.json\n",
      "2020-08-31 20:32:45,802 [INFO] file/dir created: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/requirements.txt\n",
      "2020-08-31 20:32:45,808 [INFO] file/dir created: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/wandb-history.jsonl\n",
      "2020-08-31 20:32:45,822 [INFO] file/dir created: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/wandb-events.jsonl\n",
      "2020-08-31 20:32:45,833 [INFO] file/dir modified: /home/stephenmalina/project/src/wandb/run-20200831_203242-lmpui8st/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='bpnet-training', entity='an1lam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "4LnaqSM_LM-M",
    "outputId": "aa784c6f-bc70-450d-db7e-3b5e5a677f8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dat/res-bpnet-training-2020-08-20-32-48'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config variables\n",
    "n_reps = 1\n",
    "\n",
    "# file paths\n",
    "config_dir = Path('./bpnet/') \n",
    "\n",
    "model_config_fname = 'ChIP-nexus-default.gin'\n",
    "data_config_fname = 'ChIP-nexus.dataspec.yml'\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%H-%M-%S')\n",
    "output_dir = f'../dat/res-bpnet-training-{timestamp}'\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_specs:\r\n",
      "  Oct4:\r\n",
      "    pos_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Oct4/counts.pos.bw\r\n",
      "    neg_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Oct4/counts.neg.bw\r\n",
      "    peaks: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Oct4/idr-optimal-set.summit.bed.gz\r\n",
      "  Sox2:\r\n",
      "    pos_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Sox2/counts.pos.bw\r\n",
      "    neg_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Sox2/counts.neg.bw\r\n",
      "    peaks: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Sox2/idr-optimal-set.summit.bed.gz\r\n",
      "  Nanog:\r\n",
      "    pos_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Nanog/counts.pos.bw\r\n",
      "    neg_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Nanog/counts.neg.bw\r\n",
      "    peaks: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Nanog/idr-optimal-set.summit.bed.gz\r\n",
      "  Klf4:\r\n",
      "    pos_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Klf4/counts.pos.bw\r\n",
      "    neg_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Klf4/counts.neg.bw\r\n",
      "    peaks: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Klf4/idr-optimal-set.summit.bed.gz\r\n",
      "\r\n",
      "bias_specs:\r\n",
      "  input:\r\n",
      "    pos_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/patchcap/counts.pos.bw\r\n",
      "    neg_counts: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/patchcap/counts.neg.bw\r\n",
      "    tasks:\r\n",
      "      - Oct4\r\n",
      "      - Sox2\r\n",
      "      - Nanog\r\n",
      "      - Klf4\r\n",
      "\r\n",
      "fasta_file: /home/stephenmalina/project/dat/bpnet-manuscript-data/data/mm10_no_alt_analysis_set_ENCODE.fasta\r\n"
     ]
    }
   ],
   "source": [
    "!cat {config_dir}/{data_config_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIOVdXQ9_M2q"
   },
   "source": [
    "### Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "iB2duLzl9LcR",
    "outputId": "c19db79d-1137-49e2-ef16-d06246d771c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\r\n",
      "chr10\r\n",
      "chr11\r\n",
      "chr12\r\n",
      "chr13\r\n",
      "chr14\r\n",
      "chr15\r\n",
      "chr16\r\n",
      "chr17\r\n",
      "chr18\r\n",
      "chr19\r\n",
      "chr2\r\n",
      "chr3\r\n",
      "chr4\r\n",
      "chr5\r\n",
      "chr6\r\n",
      "chr7\r\n",
      "chr8\r\n",
      "chr9\r\n",
      "chrX\r\n",
      "chrY\r\n"
     ]
    }
   ],
   "source": [
    "# chromsomome names of differnet peaks\n",
    "!zcat /home/stephenmalina/project/dat/bpnet-manuscript-data/data/chip-nexus/Sox2/idr-optimal-set.summit.bed.gz \\\n",
    "    | cut -f 1 | sort -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ok51Hx8C9rJ2"
   },
   "source": [
    "Each task (or TF) can specify a set of peaks associated with it. Here are the number of peaks per TF we will use in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "WU5wXNcS-BNn",
    "outputId": "db69a716-852b-4f31-8fcd-75f59e36eda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct4\n",
      "25849\n",
      "Sox2\n",
      "10999\n",
      "Nanog\n",
      "56459\n",
      "Klf4\n",
      "57601\n"
     ]
    }
   ],
   "source": [
    "tasks = ['Oct4', 'Sox2', 'Nanog', 'Klf4']\n",
    "\n",
    "# number of peaks per task\n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    data_dir = '/home/stephenmalina/project/dat/bpnet-manuscript-data'\n",
    "    !zcat {data_dir}/data/chip-nexus/{task}/idr-optimal-set.summit.bed.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zphiFpBT1-5G"
   },
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojWuf4Jg1_pM"
   },
   "source": [
    "Having specified `dataspec.yml`, we are now ready to train the model with \n",
    "\n",
    "```\n",
    "bpnet train <dataspec.yml> <output dir> [optional flags]`\n",
    "```\n",
    "\n",
    "\n",
    "We will use a pre-made model [bpnet9](../bpnet/premade/bpnet9.gin) as a starting point and modify a few parameters specified in the config.gin file. Specifically, we will \n",
    "- train the model only on chromosomes 16-19\n",
    "- evaluate the model on chromosome 2\n",
    "- use only 3 layers of dilated convolutions \n",
    "- use an input sequence length of 200 bp and accordingly lower the augmentation shift to 100 bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "3xFw1K-gLncD",
    "outputId": "884c5cbf-72b7-4bfc-c389-33d17ed9c07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_loss_weight = 0\r\n",
      "c_loss_weight = 10\r\n",
      "p_loss_weight = 1\r\n",
      "filters = 64\r\n",
      "tconv_kernel_size = 25\r\n",
      "lr = 0.004\r\n",
      "n_dil_layers = 9\r\n",
      "train.batch_size = 128\r\n",
      "merge_profile_reg = False\r\n",
      "dataspec = 'ChIP-nexus.dataspec.yml'\r\n",
      "\r\n",
      "batchnorm = False\r\n",
      "\r\n",
      "padding = 'same'\r\n",
      "seq_width = 1000\r\n",
      "\r\n",
      "tasks = ['Oct4', 'Sox2', 'Nanog', 'Klf4']\r\n"
     ]
    }
   ],
   "source": [
    "!cat {config_dir}/{model_config_fname} \n",
    "# NOTE: test_chr will be also excluded similar to 'exclude_chr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR51oX6LAwW9"
   },
   "source": [
    "Have a look at the original gin file of bpnet9 here: https://github.com/kundajelab/bpnet/blob/master/bpnet/premade/bpnet9-ginspec.gin. For more information on using gin files see <https://github.com/google/gin-config>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoTI8PJKLMZ9"
   },
   "source": [
    "To track model training and evaluation, we will use [wandb](http://wandb.com/) by adding `--wandb=avsec/bpnet-demo` to `bpnet train`. You can navigate to https://app.wandb.ai/avsec/bpnet-demo to see the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcS0857OAIoy"
   },
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyaAb_VqCWt0"
   },
   "outputs": [],
   "source": [
    "# setup all the file paths\n",
    "example_model_dir = os.path.join(output_dir, 'output_ensemble', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yglTmu3FrtpB",
    "outputId": "234b17b8-0e5d-4dbe-aa7e-177ef15efad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "OMP: Info #156: KMP_AFFINITY: 1 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #159: KMP_AFFINITY: 1 packages x 1 cores/pkg x 1 threads/core (1 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 3111 tid 3111 thread 0 bound to OS proc set 0\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2020-08-31 20:47:56,359 [WARNING] From /opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2020-08-31 20:47:57,033 [INFO] NumExpr defaulting to 2 threads.\n",
      "INFO [08-31 20:47:59] Using wandb. Running wandb.init()\n",
      "wandb: Tracking run with wandb version 0.9.6\n",
      "wandb: Run data is saved locally in ../dat/res-bpnet-training-2020-08-20-32-48/run-20200831_204759-2020-08-31_20-47-52_37d02a08-a509-4445-998d-7f0bd29b07d1\n",
      "wandb: Syncing run 2020-08-31_20-47-52_37d02a08-a509-4445-998d-7f0bd29b07d1\n",
      "wandb: ‚≠êÔ∏è View project at https://app.wandb.ai/an1lam/bpnet-training\n",
      "wandb: üöÄ View run at https://app.wandb.ai/an1lam/bpnet-training/runs/2020-08-31_20-47-52_37d02a08-a509-4445-998d-7f0bd29b07d1\n",
      "wandb: Run `wandb off` to turn off syncing.\n",
      "W&B Run: https://app.wandb.ai/an1lam/bpnet-training/runs/2020-08-31_20-47-52_37d02a08-a509-4445-998d-7f0bd29b07d1\n",
      "\n",
      "INFO [08-31 20:48:00] Using gpu: 0, memory fraction: 0.45\n",
      "2020-08-31 20:48:00.372725: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-08-31 20:48:00.381220: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "INFO [08-31 20:48:00] Using the following premade configuration: bpnet9\n",
      "2020-08-31 20:48:00.381778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d9ec753930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-08-31 20:48:00.381809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-08-31 20:48:00.381923: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO [08-31 20:48:00] Using the following config.gin files: ChIP-nexus-default.gin\n",
      "TF-MoDISco is using the TensorFlow backend.\n",
      "Used config: ----------------------------------------\n",
      "import bpnet\n",
      "import bpnet.configurables\n",
      "import bpnet.datasets\n",
      "import bpnet.heads\n",
      "import bpnet.layers\n",
      "import bpnet.losses\n",
      "import bpnet.metrics\n",
      "import bpnet.models\n",
      "import bpnet.seqmodel\n",
      "import bpnet.trainers\n",
      "\n",
      "# Macros:\n",
      "# ==============================================================================\n",
      "augment_interval = True\n",
      "batchnorm = False\n",
      "dataspec = 'ChIP-nexus.dataspec.yml'\n",
      "exclude_chr = ['chrX', 'chrY']\n",
      "filters = 64\n",
      "lambda = 10\n",
      "lr = 0.004\n",
      "n_bias_tracks = 2\n",
      "n_dil_layers = 9\n",
      "seq_width = 1000\n",
      "tasks = ['Oct4', 'Sox2', 'Nanog', 'Klf4']\n",
      "tconv_kernel_size = 25\n",
      "test_chr = ['chr1', 'chr8', 'chr9']\n",
      "tracks_per_task = 2\n",
      "use_bias = True\n",
      "valid_chr = ['chr2', 'chr3', 'chr4']\n",
      "\n",
      "# Parameters for Adam:\n",
      "# ==============================================================================\n",
      "Adam.amsgrad = False\n",
      "Adam.beta_1 = 0.9\n",
      "Adam.beta_2 = 0.999\n",
      "Adam.decay = 0.0\n",
      "Adam.epsilon = None\n",
      "Adam.lr = %lr\n",
      "\n",
      "# Parameters for bpnet_data:\n",
      "# ==============================================================================\n",
      "bpnet_data.augment_interval = %augment_interval\n",
      "bpnet_data.dataspec = %dataspec\n",
      "bpnet_data.exclude_chr = %exclude_chr\n",
      "bpnet_data.include_metadata = False\n",
      "bpnet_data.interval_augmentation_shift = 200\n",
      "bpnet_data.intervals_file = None\n",
      "bpnet_data.intervals_format = 'bed'\n",
      "bpnet_data.peak_width = %seq_width\n",
      "bpnet_data.seq_width = %seq_width\n",
      "bpnet_data.shuffle = True\n",
      "bpnet_data.tasks = %tasks\n",
      "bpnet_data.test_chr = %test_chr\n",
      "bpnet_data.track_transform = None\n",
      "bpnet_data.valid_chr = %valid_chr\n",
      "\n",
      "# Parameters for ClassificationMetrics:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for DeConv1D:\n",
      "# ==============================================================================\n",
      "DeConv1D.batchnorm = %batchnorm\n",
      "DeConv1D.filters = %filters\n",
      "DeConv1D.n_hidden = 0\n",
      "DeConv1D.n_tasks = %tracks_per_task\n",
      "DeConv1D.padding = 'same'\n",
      "DeConv1D.tconv_kernel_size = %tconv_kernel_size\n",
      "\n",
      "# Parameters for DilatedConv1D:\n",
      "# ==============================================================================\n",
      "DilatedConv1D.add_pointwise = False\n",
      "DilatedConv1D.batchnorm = %batchnorm\n",
      "DilatedConv1D.conv1_kernel_size = 25\n",
      "DilatedConv1D.filters = %filters\n",
      "DilatedConv1D.n_dil_layers = %n_dil_layers\n",
      "DilatedConv1D.padding = 'same'\n",
      "DilatedConv1D.skip_type = 'residual'\n",
      "\n",
      "# Parameters for GlobalAvgPoolFCN:\n",
      "# ==============================================================================\n",
      "GlobalAvgPoolFCN.batchnorm = %batchnorm\n",
      "GlobalAvgPoolFCN.dropout = 0\n",
      "GlobalAvgPoolFCN.dropout_hidden = 0\n",
      "GlobalAvgPoolFCN.hidden = None\n",
      "GlobalAvgPoolFCN.n_splines = 0\n",
      "GlobalAvgPoolFCN.n_tasks = %tracks_per_task\n",
      "\n",
      "# Parameters for IntervalAugmentor:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for MetricsOrderedDict:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for MovingAverages:\n",
      "# ==============================================================================\n",
      "MovingAverages.window_sizes = [1, 50]\n",
      "\n",
      "# Parameters for multinomial_nll:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for PeakPredictionProfileMetric:\n",
      "# ==============================================================================\n",
      "PeakPredictionProfileMetric.binsizes = [1, 10]\n",
      "PeakPredictionProfileMetric.neg_max_threshold = 0.005\n",
      "PeakPredictionProfileMetric.pos_min_threshold = 0.015\n",
      "PeakPredictionProfileMetric.required_min_pos_counts = 2.5\n",
      "\n",
      "# Parameters for ProfileHead:\n",
      "# ==============================================================================\n",
      "ProfileHead.activation = None\n",
      "ProfileHead.bias_input = 'bias/{task}/profile'\n",
      "ProfileHead.bias_net = @MovingAverages()\n",
      "ProfileHead.bias_shape = (None, %n_bias_tracks)\n",
      "ProfileHead.loss = @multinomial_nll\n",
      "ProfileHead.loss_weight = 1\n",
      "ProfileHead.metric = @PeakPredictionProfileMetric()\n",
      "ProfileHead.net = @DeConv1D()\n",
      "ProfileHead.postproc_fn = @softmax\n",
      "ProfileHead.target_name = '{task}/profile'\n",
      "ProfileHead.use_bias = %use_bias\n",
      "\n",
      "# Parameters for RegressionMetrics:\n",
      "# ==============================================================================\n",
      "# None.\n",
      "\n",
      "# Parameters for report_template:\n",
      "# ==============================================================================\n",
      "report_template.name = 'evaluate.ipynb'\n",
      "report_template.raise_error = True\n",
      "\n",
      "# Parameters for ScalarHead:\n",
      "# ==============================================================================\n",
      "ScalarHead.activation = None\n",
      "ScalarHead.bias_input = 'bias/{task}/counts'\n",
      "ScalarHead.bias_net = None\n",
      "ScalarHead.bias_shape = (%n_bias_tracks,)\n",
      "ScalarHead.loss = 'mse'\n",
      "ScalarHead.loss_weight = %lambda\n",
      "ScalarHead.metric = @RegressionMetrics()\n",
      "ScalarHead.net = @GlobalAvgPoolFCN()\n",
      "ScalarHead.postproc_fn = None\n",
      "ScalarHead.target_name = '{task}/counts'\n",
      "ScalarHead.use_bias = %use_bias\n",
      "\n",
      "# Parameters for SeqModel:\n",
      "# ==============================================================================\n",
      "SeqModel.body = @DilatedConv1D()\n",
      "SeqModel.heads = [@ProfileHead(), @ScalarHead()]\n",
      "SeqModel.input_name = 'seq'\n",
      "SeqModel.input_shape = None\n",
      "SeqModel.optimizer = @keras.optimizers.Adam()\n",
      "SeqModel.seqlen = %seq_width\n",
      "SeqModel.tasks = %tasks\n",
      "\n",
      "# Parameters for StrandedProfile:\n",
      "# ==============================================================================\n",
      "StrandedProfile.excl_chromosomes = None\n",
      "StrandedProfile.include_classes = False\n",
      "\n",
      "# Parameters for train:\n",
      "# ==============================================================================\n",
      "train.batch_size = 128\n",
      "train.data = @bpnet_data()\n",
      "train.early_stop_patience = 5\n",
      "train.epochs = 1\n",
      "train.eval_metric = None\n",
      "train.eval_report = @report_template()\n",
      "train.eval_skip = []\n",
      "train.eval_train = False\n",
      "train.model = @SeqModel()\n",
      "train.seed = 0\n",
      "train.stratified_sampler_p = None\n",
      "train.tensorboard = True\n",
      "train.train_batch_sampler = None\n",
      "train.train_epoch_frac = 1.0\n",
      "train.train_samples_per_epoch = None\n",
      "train.valid_epoch_frac = 1.0\n",
      "train.validation_samples = None\n",
      "\n",
      "----------------------------------------------------\n",
      "/opt/anaconda3/lib/python3.7/site-packages/bpnet/cli/train.py:195: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  gin_macro_dict = yaml.load(\"\\n\".join(macros).replace(\"@\", \"\").replace(\" = %\", \": \").replace(\" = \", \": \"))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/bpnet/cli/train.py:208: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  .replace(\" = \", \": \"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [09:37<00:00,  1.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 229/229 [02:33<00:00,  1.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 711/711 [07:55<00:00,  1.50it/s]\n",
      "Epoch 1/1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 3111 tid 3199 thread 1 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 3111 tid 3200 thread 2 bound to OS proc set 0\n",
      "699/710 [============================>.] - ETA: 1:19 - loss: 3500.3001 - Oct4/profile_loss: 899.3770 - Oct4/counts_loss: 0.5031 - Sox2/profile_loss: 478.7241 - Sox2/counts_loss: 0.5859 - Nanog/profile_loss: 1143.6559 - Nanog/counts_loss: 2.2988 - Klf4/profile_loss: 937.4221 - Klf4/counts_loss: 0.7243OMP: Info #250: KMP_AFFINITY: pid 3111 tid 11220 thread 3 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 12046 tid 12046 thread 3 bound to OS proc set 0\n",
      "709/710 [============================>.] - ETA: 7s - loss: 3497.2294 - Oct4/profile_loss: 898.1010 - Oct4/counts_loss: 0.5012 - Sox2/profile_loss: 478.3792 - Sox2/counts_loss: 0.5813 - Nanog/profile_loss: 1142.9263 - Nanog/counts_loss: 2.2802 - Klf4/profile_loss: 936.9721 - Klf4/counts_loss: 0.7224 OMP: Info #250: KMP_AFFINITY: pid 3111 tid 11219 thread 4 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 12180 tid 12180 thread 4 bound to OS proc set 0\n",
      "710/710 [==============================] - 5900s 8s/step - loss: 3497.2473 - Oct4/profile_loss: 898.0072 - Oct4/counts_loss: 0.5011 - Sox2/profile_loss: 478.3958 - Sox2/counts_loss: 0.5809 - Nanog/profile_loss: 1143.0598 - Nanog/counts_loss: 2.2783 - Klf4/profile_loss: 936.9597 - Klf4/counts_loss: 0.7221 - val_loss: 3322.1850 - val_Oct4/profile_loss: 829.4794 - val_Oct4/counts_loss: 0.4339 - val_Sox2/profile_loss: 463.8418 - val_Sox2/counts_loss: 0.2796 - val_Nanog/profile_loss: 1094.2659 - val_Nanog/counts_loss: 1.2958 - val_Klf4/profile_loss: 908.3772 - val_Klf4/counts_loss: 0.6127\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 108/228 [06:04<06:42,  3.36s/it]"
     ]
    }
   ],
   "source": [
    "# Train for at most 10 epochs\n",
    "for i in range(n_reps):\n",
    "    # setup a new run_id (could be done automatically, but then the output directory would change)\n",
    "    run_id = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \"_\" + str(uuid.uuid4())\n",
    "    !cd {config_dir} && bpnet train {data_config_fname} --premade=bpnet9 \\\n",
    "        --config={model_config_fname} {output_dir} \\\n",
    "        --run-id '{run_id}' --wandb=an1lam/bpnet-training --in-memory \\\n",
    "        --override='train.epochs=1; train.seed={i}'\n",
    "    # softlink the new output directory\n",
    "    !rm -f {output_dir}/output_ensemble/{i} && ln -srf {output_dir}/{run_id} {output_dir}/output_ensemble/{i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3o_U-Fu2C0fU",
    "outputId": "0be96454-bb19-48e5-ae1c-44bea6d5b271"
   },
   "outputs": [],
   "source": [
    "!ls -latr {example_model_dir}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bpnet",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
