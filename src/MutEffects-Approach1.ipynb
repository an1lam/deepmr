{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kipoi\n",
    "# !pip install kipoiseq\n",
    "# !pip install pybedtools\n",
    "# !pip uninstall -y kipoi_veff\n",
    "# !pip install git+https://github.com/an1lam/kipoi-veff\n",
    "# !pip install pyvcf\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from Bio.motifs import pfm\n",
    "import kipoi\n",
    "from kipoi_interpret.importance_scores.ism import Mutation\n",
    "from kipoiseq.dataloaders import SeqIntervalDl\n",
    "from logomaker import Logo\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import cm\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "\n",
    "from align import prob_sw\n",
    "from motif_scores import build_impact_maps\n",
    "from motif_scores import kmer_mut_scores\n",
    "from motif_scores import kmer_pwm_scores\n",
    "from motif_scores import pwm_scores\n",
    "from motif_scores import top_n_kmer_mut_scores\n",
    "from motif_scores import top_n_kmer_pwm_scores\n",
    "from np_utils import abs_max\n",
    "from pyx.one_hot import one_hot\n",
    "from utils import INT_TO_BASES\n",
    "from utils import one_hot_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/project/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DNA sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = SeqIntervalDl(\"../dat/50_random_seqs_2.bed\", \"../dat/hg19.fa\", auto_resize_len=1000)\n",
    "data = dl.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4, 1, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = np.expand_dims(data['inputs'].transpose(0, 2, 1), 2).astype(np.float32)\n",
    "seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DeepSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.15.0\n",
      "torch version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "import torch\n",
    "print(\"torch version:\", torch.__version__)\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = kipoi.list_models()\n",
    "# deepsea_models = df[df.model.str.contains(\"DeepSEA\")]\n",
    "# deepsea_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/stephenmalina/.kipoi/models/DeepSEA/predict/downloaded/model_files/weights/89e640bf6bdbe1ff165f484d9796efc7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReCodeAlphabet()\n",
       "  (1): ConcatenateRC()\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (1): Threshold(threshold=0, value=1e-06)\n",
       "    (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (5): Threshold(threshold=0, value=1e-06)\n",
       "    (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (9): Threshold(threshold=0, value=1e-06)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Lambda()\n",
       "    (12): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=50880, out_features=925, bias=True)\n",
       "    )\n",
       "    (13): Threshold(threshold=0, value=1e-06)\n",
       "    (14): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=925, out_features=919, bias=True)\n",
       "    )\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       "  (3): AverageRC()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea = kipoi.get_model(\"DeepSEA/predict\", source=\"kipoi\")\n",
    "deepsea.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROM_ACC_COL = 'HepG2_DNase_None'\n",
    "# TF_COL = 'A549_CTCF_None'\n",
    "TF_COL = 'HepG2_FOXA1_None'\n",
    "relevant_cols = sorted([(i, label)\n",
    "                        for i, label in enumerate(deepsea.schema.targets.column_labels)\n",
    "                        if label in [CHROM_ACC_COL, TF_COL]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 919)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea.pipeline.predict_example().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle_file = \"../dat/most_recent_sat_mut_results__drop_channel.pickle\"\n",
    "pickle_file = \"../dat/most_recent_sat_mut_results__original_mc_dropout.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 10, 301, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 50, 10, 301, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pickle_file, 'rb') as f: np_preds = pickle.load(f)\n",
    "print(np_preds.shape)\n",
    "epochs, n_seqs, n_batches, batch_size, _ = np_preds.shape\n",
    "np_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zeros = np.zeros((4,))\n",
    "\n",
    "def batches_needed(seq_len, batch_size, alpha_size=4):\n",
    "    assert ((seq_len * (alpha_size-1)) % (batch_size-1)) == 0, seq_len * 3\n",
    "    # alpha_size - 1 mutations per nt and then account for ref in each batch\n",
    "    return (seq_len * (alpha_size-1)) // (batch_size-1)\n",
    "\n",
    "def generate_wt_mut_batches(seq, batch_size):\n",
    "    \"\"\"\n",
    "    For a given sequence, generate all possible point-mutated versions of the sequence\n",
    "    in batches of size `param:batch_size`.\n",
    "    \n",
    "    Args:\n",
    "        seq (numpy.ndarray [number of base pairs, sequence length]): \n",
    "            wild type sequence.\n",
    "        batch_size (int): size of returned batches. Note that each batch will have the\n",
    "            wild type sequence as its first row since we need to compute wild type / mut\n",
    "            prediction diffs using predictions generated by the same dropout mask.\n",
    "    \"\"\"\n",
    "    num_nts, seq_len = seq.shape\n",
    "    n_batches = batches_needed(seq_len, batch_size, alpha_size=num_nts)\n",
    "    seq_batch = seq[np.newaxis, :, :].repeat(batch_size, axis=0)\n",
    "    seq_batches = seq_batch[np.newaxis, :, :, :].repeat(n_batches, axis=0)\n",
    "    i = 0\n",
    "    for seq_idx in range(seq_len):  # iterate over sequence \n",
    "        for nt_idx in range(num_nts):  # iterate over nucleotides\n",
    "            curr_batch, curr_idx = i // (batch_size - 1), (i % (batch_size-1) + 1)\n",
    "            \n",
    "            curr_nt = seq[nt_idx, seq_idx]\n",
    "            if int(curr_nt) == 1: continue\n",
    "\n",
    "            seq_batches[curr_batch, curr_idx, :, seq_idx] = all_zeros\n",
    "            seq_batches[curr_batch, curr_idx, nt_idx, seq_idx] = 1\n",
    "            i += 1\n",
    "    return seq_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_seq(it):\n",
    "    return (np\n",
    "            .expand_dims(next(it)[\"inputs\"].transpose(0, 2, 1), 2)\n",
    "            .astype(np.float32)\n",
    "            .squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 50 seqs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 465.69it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs, n_seqs, batch_size = 50, 25, 301\n",
    "n_nts, _, seq_len = deepsea.schema.inputs.shape\n",
    "preds = [[[] for _ in range(n_seqs)] for _ in range(epochs)]\n",
    "it = dl.batch_iter(batch_size=1, num_workers=0, drop_last=False)\n",
    "\n",
    "print(f\"Generating predictions for {len(it)} seqs\")\n",
    "n_batches = batches_needed(seq_len, batch_size, alpha_size=n_nts)\n",
    "seqs = np.zeros((n_seqs, n_nts, seq_len))\n",
    "batch_size = 301\n",
    "for i in tqdm(range(min(n_seqs, len(it)))):\n",
    "    seq = next_seq(it)\n",
    "    if np.allclose(seq, .25): raise Exception(\"shouldn't have empty seqs\")\n",
    "    seqs[i, :, :] = seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading known FOXA1 motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/Bio/motifs/pfm.py:333: FutureWarning: Possible nested set at position 15\n",
      "  row_pattern_with_nucleotide_letter = re.compile(r\"\\s*([ACGT])\\s*[[]*[|]*\\s*([0-9.\\s]+)\\s*[]]*\\s*\")\n"
     ]
    }
   ],
   "source": [
    "with open('../dat/foxa1.pfm') as f: foxa1_motifs = pfm.read(f, 'pfm-four-rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_np_pwm(pwm_map):\n",
    "    motif_len = len(list(pwm_map.values())[0])\n",
    "    np_pwm = np.zeros((len(pwm_map.keys()), motif_len))\n",
    "    for i, base in INT_TO_BASES.items(): np_pwm[i, :] = pwm_map[base]\n",
    "    return np_pwm\n",
    "        \n",
    "\n",
    "foxa1_pwm_maps = [motif.pwm for motif in foxa1_motifs]\n",
    "foxa1_pwms = [bio_to_np_pwm(pwm_map) for pwm_map in foxa1_pwm_maps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Analysis\n",
    "## Computing summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_uniform_prob = math.log(.05/(1-.05))\n",
    "def compute_normalized_prob(prob, train_prob):\n",
    "    # source: http://deepsea.princeton.edu/help/\n",
    "    denom = 1+np.exp(-(np.log(prob/(1-prob))+log_uniform_prob-np.log(train_prob/(1-train_prob))))\n",
    "    return 1 / denom\n",
    "\n",
    "# Ratios and normalization formula drawn from here: http://deepsea.princeton.edu/media/help/posproportion.txt\n",
    "tf_compute_normalized_prob = lambda prob: compute_normalized_prob(prob, 0.02394)\n",
    "chrom_acc_normalized_prob = lambda prob: compute_normalized_prob(prob, 0.049791)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_preds[:, :, :, :, 0] = chrom_acc_normalized_prob(np_preds[:, :, :, :, 0])\n",
    "np_preds[:, :, :, :, 1] = compute_normalized_prob(np_preds[:, :, :, :, 1], 0.020508)\n",
    "np_preds[:, :, :, :, 2] = compute_normalized_prob(np_preds[:, :, :, :, 2], 0.02394)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 10, 301, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = np_preds.shape[2]\n",
    "batch_size = np_preds.shape[3]\n",
    "np_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10, 301, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred_means = np.mean(np_preds[:, :, :, :, :], axis=0)\n",
    "np_pred_vars = np.var(np_preds, axis=0, dtype=np.float64)\n",
    "np_pred_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10, 300, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred_mean_diffs = np_pred_means[:, :, 1:, :] - np_pred_means[:, :, 0:1, :] \n",
    "np_pred_mean_diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pred_covs = np.zeros((n_seqs, n_batches, batch_size, 2, 2, len(relevant_cols)))\n",
    "for seq in range(n_seqs):\n",
    "    for batch in range(n_batches):\n",
    "        for col in range(len(relevant_cols)):\n",
    "            ref_seq_preds = np_preds[:, seq, batch, 0, col]\n",
    "            for mut in range(batch_size):\n",
    "                mut_seq_preds = np_preds[:, seq, batch, mut, col]\n",
    "                cov = np.cov(np.stack((ref_seq_preds, mut_seq_preds)), ddof=0) # 2x2, symmetric\n",
    "                np_pred_covs[seq, batch, mut, :, :, col] = cov # off diag idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pred_uncertainties = np.sqrt(\n",
    "    np_pred_covs[:, :, 1:, 1, 1, :] + np_pred_covs[:, :, 1:, 0, 0, :] - 2 * np_pred_covs[:, :, 1:, 0, 1, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3, 2000, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred_mean_diffs = np_pred_mean_diffs.reshape(n_seqs, n_nts-1, -1, 3)\n",
    "np_pred_mean_diffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Mutation Impact to Known Binding Motif Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_effects = np_pred_mean_diffs[:, :, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_scores = pwm_scores(foxa1_pwms, seqs)\n",
    "seq_scores = [np.concatenate((scores, np.zeros((25, 1000 - scores.shape[1]))), axis=1) for scores in seq_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4, 1000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_maps = build_impact_maps(seqs, mut_effects)\n",
    "impact_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_scores = abs_max(impact_maps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(foxa1_pwms) * n_seqs\n",
    "top_in_window = 0\n",
    "\n",
    "for i in range(len(foxa1_pwms)):\n",
    "    for j in range(n_seqs):\n",
    "        seq_score_idxs = np.argsort(seq_scores[i][j])\n",
    "        window_start, window_end = seq_score_idxs[-1], seq_score_idxs[-1] + foxa1_pwms[i].shape[1]\n",
    "        best_mut_idxs = np.argsort(np.abs(mut_scores[j]))[-5:]\n",
    "        if np.any(best_mut_idxs >= window_start) and np.any(best_mut_idxs < window_end): top_in_window += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 0.46)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_in_window, top_in_window / float(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
