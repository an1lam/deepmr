{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import simdna\n",
    "from simdna import synthetic\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import one_hot_decode\n",
    "from in_silico_mutagenesis import compute_summary_statistics, generate_wt_mut_batches, write_results\n",
    "from pyx.one_hot import one_hot\n",
    "from tf_coop_model import CountsRegressor, IterablePandasDataset\n",
    "from tf_coop_model import anscombe_transform, run_one_epoch, spearman_rho, pearson_r\n",
    "from tf_coop_simulation import background_frequency\n",
    "from tf_coop_simulation import simulate_counts, simulate_oracle_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/anaconda3/envs/deepmr/lib/python3.6/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model & Load Weights\n",
    "This step assumes we've trained a counts regression model and have its weights stored in a .pt[h] file somewhere accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 3\n",
    "n_dense_layers = 3\n",
    "n_outputs = 2\n",
    "sequence_length = 100\n",
    "filters = 15\n",
    "filter_width = 7\n",
    "dense_layer_width = 30\n",
    "\n",
    "weights_dir = '../dat/sim/'\n",
    "weights_fname = 'cnn_counts_predictor.pt'\n",
    "test_data_fpath = '../dat/sim/test_labels.csv'\n",
    "raw_simulation_data_fpath = '../dat/sim/test_sequences.simdata'\n",
    "\n",
    "sequences_col = \"sequences\"\n",
    "label_cols = [\"labels_exp\", \"labels_out\"]\n",
    "batch_size = 1000\n",
    "n_samples = 10\n",
    "\n",
    "exposure_motif = \"GATA_disc1\"\n",
    "outcome_motif = \"TAL1_known1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f952968f860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, model_base_dir, model_fname, model_params, n_reps=5):\n",
    "        models = []\n",
    "        for i in range(1, n_reps+1):\n",
    "            model = CountsRegressor(**params)\n",
    "            model.load_state_dict(torch.load(os.path.join(model_base_dir, str(i), model_fname)))\n",
    "            models.append(model)\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, seqs, targets=None):\n",
    "        preds = {}\n",
    "        for model in self.models:\n",
    "            model_preds = model(seqs, targets=targets)\n",
    "            for key, preds_ in model_preds.items():\n",
    "                preds.setdefault(key, []).append(preds_.detach().cpu().numpy())\n",
    "        return {k: np.stack(v) for k, v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Ensemble at 0x7f94bbfb27b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_conv_layers\": n_conv_layers,\n",
    "    \"n_dense_layers\": n_dense_layers,\n",
    "    \"n_outputs\": n_outputs,\n",
    "    \"sequence_length\": sequence_length,\n",
    "    \"filters\": filters,\n",
    "    \"filter_width\": filter_width,\n",
    "    \"dense_layer_width\": dense_layer_width\n",
    "}\n",
    "ensemble_model = Ensemble(weights_dir, \"cnn_counts_predictor.pt\", params)\n",
    "ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data & Generate Predictions\n",
    "Now we're going to load test data to get some basic metrics about how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_fpath)\n",
    "test_dataset = IterablePandasDataset(\n",
    "    test_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Deep MR\n",
    "In Shrikumar et al, all effects are computed in raw counts space. Here, for purposes of making our result relevant to Deep MR, we compute interaction effects in both Anscombe-transformed space and raw counts space but focus on the validity of the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_simulation_df = pd.read_csv(raw_simulation_data_fpath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data_df = original_simulation_df.merge(test_df, left_on=\"sequence\", right_on=\"sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_df = merged_data_df[(merged_data_df['has_exposure'] == 1) & (merged_data_df['has_outcome'] == 1)]\n",
    "exposure_motif_df = merged_data_df[merged_data_df['has_exposure'] == 1]\n",
    "outcome_motif_df = merged_data_df[merged_data_df['has_outcome'] == 1]\n",
    "neither_motif_df = merged_data_df[\n",
    "    (merged_data_df['has_exposure'] == 0) & (merged_data_df['has_outcome'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 5029, 4990, 2469)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_motifs_df), len(exposure_motif_df), len(outcome_motif_df), len(neither_motif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_dataset = IterablePandasDataset(\n",
    "    both_motifs_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    ")\n",
    "both_motifs_data_loader = torch.utils.data.DataLoader(\n",
    "    both_motifs_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_and_predict(model, sample_dataset):\n",
    "    preds = {}\n",
    "    all_muts = []\n",
    "    for seq, label in tqdm(sample_dataset):\n",
    "        muts = generate_wt_mut_batches(seq, seq.shape[0] * seq.shape[1]).squeeze()\n",
    "        muts = muts.transpose(0, 1, 2)\n",
    "        muts = torch.from_numpy(muts)\n",
    "        label = torch.from_numpy(label)\n",
    "        preds_ = model.predict(muts, targets=label)['predictions']\n",
    "        exposure_preds = preds_[:, :, 0]\n",
    "        outcome_preds = preds_[:, :, 1]\n",
    "        preds.setdefault('exposure', []).append(exposure_preds)\n",
    "        preds.setdefault('outcome', []).append(outcome_preds)\n",
    "        all_muts.append(muts.detach().cpu().numpy())\n",
    "    return all_muts, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_sample_dataset, _ = torch.utils.data.random_split(\n",
    "    both_motifs_dataset, (n_samples, len(both_motifs_dataset) - n_samples)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d3aa0f465b444f952acf471b24097e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2488.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/anaconda3/envs/deepmr/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([400, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "muts, preds = mutate_and_predict(ensemble_model, both_motifs_dataset)\n",
    "sample_seqs = [seq for seq, label in both_motifs_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edfa544058b418face7fda28c77c603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2488.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exposure_col = \"exposure\"\n",
    "outcome_col = \"outcome\"\n",
    "\n",
    "formatted_preds = np.stack((preds[exposure_col], preds[outcome_col]))\n",
    "n_features, n_seqs, n_reps, n_variants = formatted_preds.shape\n",
    "formatted_preds = formatted_preds.transpose(2, 1, 3, 0)\n",
    "formatted_preds = formatted_preds.reshape(n_reps, n_seqs, 4, -1, n_features)\n",
    "\n",
    "means, mean_diffs, stderrs = compute_summary_statistics(formatted_preds, np.array(sample_seqs))\n",
    "\n",
    "results_fname = f'GATA_TAL1_effect_sizes_v2.csv'\n",
    "results_fpath = os.path.join('../dat/sim', results_fname)\n",
    "write_results(results_fpath, mean_diffs, stderrs)\n",
    "print(results_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cis = []\n",
    "for i in range(len(sample_seqs)):\n",
    "    x = sm.add_constant(diffs[i, :, :, 0].flatten(), prepend=False)\n",
    "    y = adjusted_diffs[i, :, :, 1].flatten()\n",
    "    ols_res = sm.OLS(y, x).fit()\n",
    "    seq_cis.append(ols_res.params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cis[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepmr)",
   "language": "python",
   "name": "deepmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
