{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/project/src/motif_scores.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# !pip install kipoi\n",
    "# !pip install kipoiseq\n",
    "# !pip install pybedtools\n",
    "# !pip uninstall -y kipoi_veff\n",
    "# !pip install git+https://github.com/an1lam/kipoi-veff\n",
    "# !pip install pyvcf\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import kipoi\n",
    "from kipoi_interpret.importance_scores.ism import Mutation\n",
    "from kipoiseq.dataloaders import SeqIntervalDl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_dropout import LockedWeightDropout\n",
    "from in_silico_mutagenesis import compute_summary_statistics\n",
    "from in_silico_mutagenesis import filter_predictions_to_matching_cols\n",
    "from in_silico_mutagenesis import mutate_and_predict\n",
    "from in_silico_mutagenesis import deepsea_normalizers\n",
    "from motif_scores import build_impact_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/project/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DNA sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = SeqIntervalDl(\"../dat/50_random_seqs_2.bed\", \"../dat/hg19.fa\", auto_resize_len=1000)\n",
    "data = dl.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4, 1, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seqs = 50\n",
    "seqs = np.expand_dims(data['inputs'].transpose(0, 2, 1), 2).astype(np.float32)\n",
    "seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DeepSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.15.0\n",
      "torch version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "import torch\n",
    "print(\"torch version:\", torch.__version__)\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = kipoi.list_models()\n",
    "# deepsea_models = df[df.model.str.contains(\"DeepSEA\")]\n",
    "# deepsea_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/stephenmalina/.kipoi/models/DeepSEA/predict/downloaded/model_files/weights/89e640bf6bdbe1ff165f484d9796efc7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReCodeAlphabet()\n",
       "  (1): ConcatenateRC()\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (1): Threshold(threshold=0, value=1e-06)\n",
       "    (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (5): Threshold(threshold=0, value=1e-06)\n",
       "    (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (9): Threshold(threshold=0, value=1e-06)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Lambda()\n",
       "    (12): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=50880, out_features=925, bias=True)\n",
       "    )\n",
       "    (13): Threshold(threshold=0, value=1e-06)\n",
       "    (14): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=925, out_features=919, bias=True)\n",
       "    )\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       "  (3): AverageRC()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea = kipoi.get_model(\"DeepSEA/predict\", source=\"kipoi\")\n",
    "deepsea.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 919)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea.pipeline.predict_example().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking DeepSEA's layers\n",
    "This section is focused on tweaking DeepSEA's model to use dropout when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_dropout import apply_dropout, replace_dropout_layers, unapply_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReCodeAlphabet()\n",
       "  (1): ConcatenateRC()\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (1): Threshold(threshold=0, value=1e-06)\n",
       "    (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): LockedWeightDropout(p=0.2)\n",
       "    (4): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (5): Threshold(threshold=0, value=1e-06)\n",
       "    (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): LockedWeightDropout(p=0.2)\n",
       "    (8): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (9): Threshold(threshold=0, value=1e-06)\n",
       "    (10): LockedWeightDropout(p=0.5)\n",
       "    (11): Lambda()\n",
       "    (12): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=50880, out_features=925, bias=True)\n",
       "    )\n",
       "    (13): Threshold(threshold=0, value=1e-06)\n",
       "    (14): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=925, out_features=919, bias=True)\n",
       "    )\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       "  (3): AverageRC()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea.model = replace_dropout_layers(deepsea.model, dropout_cls=LockedWeightDropout)\n",
    "deepsea.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few preds (1/3):  [[0.08620486 0.07117724 0.08076133 ... 0.07425417 0.0193945  0.01526004]\n",
      " [0.04501081 0.00637511 0.02325991 ... 0.0854755  0.04083367 0.00989448]\n",
      " [0.04042565 0.0047662  0.01646545 ... 0.11744817 0.3626911  0.02936701]\n",
      " [0.00452696 0.00096715 0.0054947  ... 0.01194064 0.04566119 0.00112314]\n",
      " [0.00078801 0.01083222 0.00274182 ... 0.01452547 0.05021808 0.02226263]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few preds (2/3):  [[0.13888726 0.10015524 0.18727924 ... 0.11640857 0.02568786 0.01024848]\n",
      " [0.0296017  0.00411213 0.02697972 ... 0.12137947 0.07428952 0.00958387]\n",
      " [0.05480719 0.00542989 0.02732315 ... 0.16602823 0.40117437 0.02221408]\n",
      " [0.00295882 0.00070132 0.00334569 ... 0.00829488 0.04764904 0.00081818]\n",
      " [0.00103597 0.00698191 0.00252939 ... 0.01807006 0.07374699 0.02256136]]\n"
     ]
    }
   ],
   "source": [
    "deepsea.model.eval()\n",
    "deepsea.model = deepsea.model.apply(apply_dropout)\n",
    "for i in range(2):\n",
    "    print(f\"First few preds ({i+1}/3): \", deepsea.pipeline.predict_example()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and in-silico mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56, 'HepG2_DNase_None'),\n",
       " (302, 'HepG2_FOXA1_None'),\n",
       " (303, 'HepG2_FOXA1_None')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHROM_ACC_COL_NAME = 'HepG2_DNase_None'\n",
    "TF_COL_NAME = 'HepG2_FOXA1_None'\n",
    "relevant_cols = sorted([(i, label)\n",
    "                        for i, label in enumerate(deepsea.schema.targets.column_labels)\n",
    "                        if label in [CHROM_ACC_COL_NAME, TF_COL_NAME]])\n",
    "\n",
    "def output_sel_fn(result):\n",
    "    return np.array([result[:, col_idx] for col_idx, _ in relevant_cols]).T\n",
    "\n",
    "relevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01526428, 0.0424991 , 0.05411917],\n",
       "        [0.16690652, 0.24805285, 0.25762313],\n",
       "        [0.01931094, 0.20745062, 0.22377067],\n",
       "        [0.10558871, 0.24706267, 0.21349985],\n",
       "        [0.06866537, 0.21062837, 0.21415865]]),\n",
       " array([[0.00434706, 0.02149264, 0.02725211],\n",
       "        [0.0551964 , 0.08321126, 0.08422774],\n",
       "        [0.00912663, 0.09612338, 0.10262818],\n",
       "        [0.02354572, 0.0866553 , 0.07790363],\n",
       "        [0.0339381 , 0.08284483, 0.08277552]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_preds = np.zeros((50, 5, 3))\n",
    "\n",
    "for i in range(50):\n",
    "    sample_preds[i] = output_sel_fn(deepsea.predict_on_batch(seqs[:5, :, :, ]))\n",
    "    \n",
    "np.mean(sample_preds, axis=0), np.std(sample_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(56, 'HepG2_DNase_None'), (302, 'HepG2_FOXA1_None'), (303, 'HepG2_FOXA1_None')]\n"
     ]
    }
   ],
   "source": [
    "CA_COL, TF_COL = 0, 1\n",
    "print(relevant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs, batch_size = 50, 400\n",
    "# preds = mutate_and_predict(\n",
    "#     deepsea,\n",
    "#     seqs.squeeze(),\n",
    "#     epochs,\n",
    "#     batch_size,\n",
    "#     output_sel_fn=filter_predictions_to_matching_cols(relevant_cols),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '50_random_seqs__new_code_comparison__all_50.pickle'\n",
    "# with open(pickle_file, 'wb') as f: pickle.dump(preds, f)\n",
    "with open(pickle_file, 'rb') as f: preds = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seqs, n_nts, seq_len = seqs.squeeze().shape\n",
    "for i, (_, col_name) in enumerate(relevant_cols):\n",
    "    preds[:, :, :, i] = deepsea_normalizers[col_name](preds[:, :, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 4, 1000, 3), (50, 3, 1000, 3), (50, 3, 1000, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = seqs.squeeze()\n",
    "means, mean_diffs, stderrs = compute_summary_statistics(preds, seqs)\n",
    "means.shape, mean_diffs.shape, stderrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.7794337e-02, -2.0613831e-02, -2.3787150e-02],\n",
       "        [ 1.7941456e-02,  2.0779006e-02,  2.3977324e-02],\n",
       "        [-2.8421543e-06,  8.3847717e-06,  8.1231628e-06],\n",
       "        ...,\n",
       "        [-3.6705895e-03, -4.6688779e-03, -5.6366897e-03],\n",
       "        [-2.9608670e-03, -4.6098167e-03, -5.5397470e-03],\n",
       "        [-3.5773423e-03, -4.8489608e-03, -5.8090449e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diffs[5, 0:1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.62715729e-05, 8.27754122e-05, 1.00361242e-04],\n",
       "        [2.57414295e-03, 9.36752952e-03, 1.13420430e-02],\n",
       "        [2.57570270e-03, 9.38007443e-03, 1.13569942e-02],\n",
       "        ...,\n",
       "        [7.16946828e-03, 3.18609004e-02, 3.94315857e-02],\n",
       "        [6.90317177e-03, 3.02027463e-02, 3.73925598e-02],\n",
       "        [7.16854883e-03, 3.18602334e-02, 3.94305002e-02]],\n",
       "\n",
       "       [[6.33409948e-03, 2.36049141e-02, 2.93885944e-02],\n",
       "        [6.28016033e-03, 2.34820330e-02, 2.93093734e-02],\n",
       "        [6.22728901e-03, 2.33578817e-02, 2.91674253e-02],\n",
       "        ...,\n",
       "        [7.90300704e-03, 3.56890154e-02, 4.39618763e-02],\n",
       "        [7.93364198e-03, 3.63152302e-02, 4.47840597e-02],\n",
       "        [7.84416806e-03, 3.54790183e-02, 4.38411898e-02]],\n",
       "\n",
       "       [[6.74883461e-03, 2.91956653e-02, 3.59537360e-02],\n",
       "        [6.48573313e-03, 2.86416257e-02, 3.51736459e-02],\n",
       "        [6.60402711e-03, 2.87510889e-02, 3.53865194e-02],\n",
       "        ...,\n",
       "        [4.97977249e-06, 1.15375907e-05, 2.29673400e-05],\n",
       "        [4.01524721e-06, 1.05261454e-05, 1.40533920e-05],\n",
       "        [3.99400266e-06,            nan, 2.06193643e-05]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stderrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, n_seqs = 50, 50\n",
    "\n",
    "epoch_seq_idxs = seqs[np.newaxis, :].repeat(epochs, axis=0).astype(np.bool)\n",
    "ref_preds = preds[epoch_seq_idxs].reshape(epochs, n_seqs, 1, seq_len, -1)\n",
    "mut_preds = preds[~epoch_seq_idxs].reshape(epochs, n_seqs, n_nts - 1, seq_len, -1)\n",
    "\n",
    "seq_idxs = seqs.astype(np.bool)\n",
    "ref_means = means[seq_idxs].reshape(n_seqs, 1, seq_len, -1)\n",
    "mut_means = means[~seq_idxs].reshape(n_seqs, n_nts - 1, seq_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dat/most_recent_sat_mut_results__comparison.pickle', 'rb') as f: original_preds = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 25, 10, 301, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 4, 1000, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 1, 1000, 1, 3), (25, 3, 1000, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_original_seqs = 25\n",
    "n_batches = original_preds.shape[2]\n",
    "original_ref_preds = original_preds[:, :, :, 0:1, :]\n",
    "origina_ref_preds = original_ref_preds.reshape(epochs, n_original_seqs, -1, len(relevant_cols))\n",
    "original_ref_preds = original_ref_preds.repeat(seq_len // n_batches, axis=2)\n",
    "original_ref_preds = np.expand_dims(original_ref_preds, axis=2)\n",
    "original_mut_preds = original_preds[:, :, :, 1:, :].reshape(\n",
    "    epochs, n_original_seqs, n_nts-1, seq_len, len(relevant_cols)\n",
    ")\n",
    "\n",
    "original_ref_means = np.mean(original_ref_preds, axis=0)\n",
    "original_mut_means = np.mean(original_mut_preds, axis=0)\n",
    "\n",
    "original_ref_means.shape, original_mut_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50,25,4,1000,3) (50,25,4,1,1000,1,3) (50,25,4,1,1000,1,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a8d14f6f8941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_original_ref_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmasked_original_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_seq_pred_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_original_ref_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmasked_original_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_seq_pred_idxs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_mut_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50,25,4,1000,3) (50,25,4,1,1000,1,3) (50,25,4,1,1000,1,3) "
     ]
    }
   ],
   "source": [
    "epoch_seq_idx\n",
    "epoch_seq_pred_idxs = np.expand_dims(, axis=-1).repeat(preds.shape[-1], axis=-1)\n",
    "masked_original_ref_preds = np.expand_dims(original_ref_preds, axis=2).repeat(n_nts, axis=2)\n",
    "mask = np.zeros_like(masked_original_ref_preds)\n",
    "\n",
    "masked_original_preds = np.where(epoch_seq_pred_idxs, masked_original_ref_preds, mask)\n",
    "masked_original_preds[np.where(epoch_seq_pred_idxs == 0)] = original_mut_preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_means, original_mean_diffs, original_stderrs = compute_summary_statistics(masked_original_preds, seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.std(means - original_means))\n",
    "plt.scatter(means.flatten(), original_means.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import auc, brier_score_loss, roc_auc_score, roc_curve\n",
    "from sklearn.calibration import calibration_curve \n",
    "\n",
    "score = roc_auc_score(\n",
    "    np.concatenate((np.ones(25), np.zeros(25))),\n",
    "    ref_means[:, 0, 0, 1],\n",
    ")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(\n",
    "    np.concatenate((np.ones(25), np.zeros(25))),\n",
    "    ref_means[:, 0, 0, 1],\n",
    ")\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (TF binding)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate((np.ones(25), np.zeros(25)))\n",
    "prob_pos = ref_means[:, 0, 0, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test,\n",
    "    prob_pos,\n",
    "    n_bins=10\n",
    ")\n",
    "clf_score = brier_score_loss(y_test, prob_pos)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "     label=\"%s (%1.3f)\" % (\"MC dropout predictive means (TF)\", clf_score))\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "# ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "#          histtype=\"step\", lw=2)\n",
    "prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prob_pos, range=(0, 1), bins=10, label=\"Predictive means (TF)\",\n",
    "          histtype=\"step\", lw=2)\n",
    "plt.hist(ref_means[:, 0, 0, 0], range=(0, 1), bins=10, label=\"Predictive means (CA)\",\n",
    "          histtype=\"step\", lw=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate((np.ones(25), np.zeros(25)))\n",
    "prob_pos = ref_means[:, 0, 0, 0]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test,\n",
    "    prob_pos,\n",
    "    n_bins=10\n",
    ")\n",
    "clf_score = brier_score_loss(y_test, prob_pos)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "     label=\"%s (%1.3f)\" % (\"MC dropout predictive means (CA)\", clf_score))\n",
    "plt.ylabel(\"Fraction of positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 20))\n",
    "plt.suptitle(\"Predictive Means (Ref)\")\n",
    "\n",
    "ax1.hist(\n",
    "    (ref_means[:25, 0, 0, TF_COL].reshape(-1),\n",
    "     ref_means[25:, 0, 0, TF_COL].reshape(-1)),\n",
    "    label=(\"binding\", \"no binding\"))\n",
    "ax1.set_title(f\"TF {relevant_cols[1][1]}\")\n",
    "ax1.legend()\n",
    "ax2.hist(\n",
    "    (ref_means[:25, 0, 0, CA_COL].reshape(-1),\n",
    "     ref_means[25:, 0, 0, CA_COL].reshape(-1)),\n",
    "    label=(\"accessible\", \"not accessible\"))\n",
    "ax2.set_title(f\"DNase {relevant_cols[0][1]}\")\n",
    "ax2.legend()\n",
    "\n",
    "fig.text(0.5, 0.08, \"Predictive Means for y=0 vs y=1\", ha=\"center\")\n",
    "fig.text(0.07, 0.5, \"# of Seqs\", va='center', rotation='vertical')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "sample_seq = 4\n",
    "sample_pred_diffs = (mut_preds[:, sample_seq, :, :, :] - ref_preds[:, sample_seq, :, :, :]).reshape(epochs, -1)\n",
    "sample_std_errs = stderrs[sample_seq, :, :, :].reshape(-1)\n",
    "sample_mean_diffs = mean_diffs[sample_seq, :, :, :].reshape(-1)\n",
    "normalized_preds = (sample_pred_diffs - sample_mean_diffs) / sample_std_errs\n",
    "\n",
    "res = stats.probplot(normalized_preds[:, :].reshape(-1), plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-CA Relationship and Mutation Effect Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
    "plt.suptitle(\"Predictive Mean Diffs (Mut vs. Ref)\")\n",
    "\n",
    "ax1.hist(\n",
    "    (mean_diffs[:25, :, :, 1].reshape(-1),\n",
    "     mean_diffs[25:, :, :, 1].reshape(-1)),\n",
    "    label=(\"binding\", \"no binding\"),\n",
    "    log=True)\n",
    "ax1.set_title(f\"TF {relevant_cols[1][1]}\")\n",
    "ax1.legend()\n",
    "ax2.hist(\n",
    "    (mean_diffs[:25, :, :, 0].reshape(-1),\n",
    "     mean_diffs[25:, :, :, 0].reshape(-1)),\n",
    "    label=(\"binding\", \"no binding\"),\n",
    "    log=True)\n",
    "ax2.set_title(f\"DNase {relevant_cols[2][1]}\")\n",
    "ax2.legend()\n",
    "\n",
    "fig.text(0.5, 0.08, \"Predictive Mean Diff\", ha=\"center\")\n",
    "fig.text(0.07, 0.5, \"# of Seqs\", va='center', rotation='vertical')\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_COL = 1\n",
    "CA_COL = 0\n",
    "\n",
    "fig, ((ax11, ax12), (ax21, ax22)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "plt.suptitle(\"S.E. vs. Predictive Mean Diff (TF)\")\n",
    "\n",
    "for seq in range(n_seqs):\n",
    "    ax11.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        stderrs[seq, :, :, TF_COL].reshape(-1))\n",
    "    ax11.set_title(f\"{relevant_cols[1][1]} (binding)\")\n",
    "\n",
    "for seq in range(n_seqs // 2, n_seqs):\n",
    "    ax12.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        stderrs[seq, :, :, TF_COL].reshape(-1))\n",
    "    ax12.set_title(f\"{relevant_cols[1][1]} (no binding)\")\n",
    "    \n",
    "for seq in range(n_seqs):\n",
    "    ax21.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        stderrs[seq, :, :, TF_COL].reshape(-1))\n",
    "    ax21.set_title(f\"{relevant_cols[0][1]} (binding)\")\n",
    "\n",
    "for seq in range(n_seqs // 2, n_seqs):\n",
    "    ax22.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        stderrs[seq, :, :, TF_COL].reshape(-1))\n",
    "    ax22.set_title(f\"{relevant_cols[0][1]} (no binding)\")\n",
    "    \n",
    "fig.text(0.5, 0.08, \"Predictive Mean Diff\", ha=\"center\")\n",
    "fig.text(0.07, 0.5, \"Predictive S.E.\", va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_binding_seqs = 25\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
    "plt.suptitle(\"CA predictive mean diff vs. TF predictive mean diff\")\n",
    "for seq in range(n_binding_seqs):\n",
    "    title, ax = (\"(binding)\", ax1) if seq < n_binding_seqs else (\"(no binding)\", ax1)\n",
    "    ax1.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        mean_diffs[seq, :, :, CA_COL].reshape(-1), \n",
    "        label=seq)\n",
    "    if seq < n_binding_seqs: ax1.set_title(\"(binding)\")\n",
    "    ax1.legend()\n",
    "\n",
    "for seq in range(n_binding_seqs, n_seqs):\n",
    "    ax2.scatter(\n",
    "        mean_diffs[seq, :, :, TF_COL].reshape(-1), \n",
    "        mean_diffs[seq, :, :, CA_COL].reshape(-1), \n",
    "        label=seq)\n",
    "    ax2.set_title(\"(no binding)\")\n",
    "    ax2.legend()\n",
    "fig.text(0.5, 0.08, \"TF Predictive Mean Diff\", ha=\"center\")\n",
    "fig.text(0.07, 0.5, \"CA Predictive Mean Diff\", va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from matplotlib import cm\n",
    "\n",
    "cols, margin = 3, 10 # margin determined empirically\n",
    "fig, axs = plt.subplots(math.ceil(n_seqs / float(cols)), cols, figsize=(16, n_seqs + margin))\n",
    "\n",
    "\n",
    "for i in range(n_seqs):\n",
    "    sample_mut_preds = original_mut_preds[:, i, :, :, TF_COL]\n",
    "    sample_ref_preds = original_ref_preds[:, i, :, :, TF_COL].repeat(3, axis=1)\n",
    "    colors = (\n",
    "        (sample_mut_preds.ravel() - sample_mut_preds.mean())**2 + \n",
    "        (sample_ref_preds.ravel() - sample_ref_preds.mean())**2\n",
    "    )\n",
    "    ax = axs[i // cols, i % cols]\n",
    "    ax.hexbin(\n",
    "        sample_ref_preds.ravel(), \n",
    "        sample_mut_preds.ravel(), \n",
    "        C=colors,\n",
    "        cmap=cm.jet,\n",
    "        bins=None,\n",
    "    )\n",
    "    xq1, xq2 = np.quantile(sample_ref_preds, (.25, .75))\n",
    "    yq1, yq2 = np.quantile(sample_mut_preds, (.25, .75))\n",
    "    rect = patches.Rectangle((xq1, yq1), xq2 - xq1, yq2 - yq1, fill=False, edgecolor='black')\n",
    "    rect = ax.add_patch(rect)\n",
    "    xlabel = \"seq {i} ref (std: {stddev:.3f})\".format(i=i, stddev=np.std(sample_ref_preds))\n",
    "    ylabel = \"seq {i} mut (std: {stddev:.3f})\".format(i=i, stddev=np.std(sample_mut_preds))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "\n",
    "\n",
    "cols, margin = 3, 20 # margin determined empirically\n",
    "fig, axs = plt.subplots(math.ceil(n_seqs / float(cols)), cols, figsize=(16, n_seqs + margin))\n",
    "# plt.suptitle(\"CA predictive mean diff vs. TF predictive mean diff\")\n",
    "slopes = []\n",
    "rsquareds = []\n",
    "\n",
    "n_binding_seqs = 25\n",
    "for seq in range(n_seqs):\n",
    "    ax = axs[seq // cols, seq % cols]\n",
    "    \n",
    "    x, y = mean_diffs[seq, :, :, TF_COL].reshape(-1), mean_diffs[seq, :, :, CA_COL].reshape(-1)\n",
    "    xc = sm.add_constant(x)\n",
    "    model = sm.OLS(y, xc)\n",
    "    result = model.fit()\n",
    "    intercept, slope = result.params\n",
    "    slopes.append(slope)\n",
    "    rsquared = result.rsquared\n",
    "    rsquareds.append(rsquared)\n",
    "    stderr = result.bse[1]\n",
    "    \n",
    "    title = \"%d - \" % (seq)\n",
    "    title += \" (b) \" if seq < n_binding_seqs else \" (nb)\"\n",
    "    title += \"(slope: %.2f, r^2: %.3f, std: %.4f)\" % (slope, rsquared, stderr)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    line = slope*x+intercept\n",
    "    prstd, iv_l, iv_u = wls_prediction_std(result)\n",
    "    ax.plot(x, line, 'r')\n",
    "    ax.plot(x, y, 'o')\n",
    "    ax.plot(x, iv_u, 'r--')\n",
    "    ax.plot(x, iv_l, 'r--')\n",
    "    legend = ax.legend(loc=\"best\")\n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(slopes) / len(slopes))\n",
    "print(sum(rsquareds) / len(rsquareds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TO_NT = 'ACGT'\n",
    "\n",
    "def _convert_to_mutation(pos_nt_pair):\n",
    "    return \"%d%s\" % (pos_nt_pair[0], IDX_TO_NT[pos_nt_pair[1]])\n",
    "\n",
    "\n",
    "TF_COL = 1\n",
    "CA_COL = 0\n",
    "\n",
    "def _write_row(writer, seq_idx, x_eff_size, y_eff_size, x_stderr, y_stderr):\n",
    "    writer.writerow(\n",
    "        {\n",
    "            \"seq_num\": seq_idx + 1,\n",
    "            \"X_pred_mean\": x_eff_size,\n",
    "            \"X_pred_var\": x_stderr,\n",
    "            \"Y_pred_mean\": y_eff_size,\n",
    "            \"Y_pred_var\": y_stderr,\n",
    "        }\n",
    "    )\n",
    "        \n",
    "\n",
    "with open(\"../dat/means_and_uncertainties_new_code_2.csv\", 'w', newline=\"\") as out_file:\n",
    "    fieldnames = [\n",
    "        \"seq_num\",\n",
    "        \"mut\",\n",
    "        \"X_pred_mean\",\n",
    "        \"X_pred_var\",\n",
    "        \"Y_pred_mean\",\n",
    "        \"Y_pred_var\",\n",
    "    ]\n",
    "    writer = csv.DictWriter(out_file, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for seq_idx in range(n_seqs // 2):\n",
    "        for seq_pos in range(seq_len):\n",
    "            for nt_pos in range(n_nts-1):\n",
    "                x_eff_size = mean_diffs[seq_idx, nt_pos, seq_pos, TF_COL]\n",
    "                y_eff_size = mean_diffs[seq_idx, nt_pos, seq_pos, CA_COL]\n",
    "                x_stderr = stderrs[seq_idx, nt_pos, seq_pos, TF_COL]\n",
    "                y_stderr = stderrs[seq_idx, nt_pos, seq_pos, CA_COL]\n",
    "                _write_row(writer, seq_idx, x_eff_size, y_eff_size, x_stderr, y_stderr)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
