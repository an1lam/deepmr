{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/deepmr-bpnet3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:59:13,540 [WARNING] From /home/ubuntu/anaconda3/envs/deepmr-bpnet3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2022-06-29 11:59:13,890 [INFO] NumExpr defaulting to 4 threads.\n",
      "2022-06-29 11:59:15,064 [WARNING] Unrecognized fields for DataLoaderDescription: {'postprocessing'}. Available fields are {'dependencies', 'path', 'args', 'writers', 'defined_as', 'type', 'output_schema', 'info'}\n",
      "2022-06-29 11:59:15,078 [WARNING] Unrecognized fields for DataLoaderDescription: {'postprocessing'}. Available fields are {'dependencies', 'path', 'args', 'writers', 'defined_as', 'type', 'output_schema', 'info'}\n",
      "2022-06-29 11:59:15,118 [WARNING] Unrecognized fields for DataLoaderDescription: {'postprocessing'}. Available fields are {'dependencies', 'path', 'args', 'writers', 'defined_as', 'type', 'output_schema', 'info'}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import detect_device\n",
    "import uncertainty_toolbox\n",
    "import uncertainty_toolbox.data as udata\n",
    "import uncertainty_toolbox.metrics as umetrics\n",
    "from uncertainty_toolbox.metrics_calibration import (\n",
    "    get_proportion_lists_vectorized,\n",
    ")\n",
    "import uncertainty_toolbox.viz as uviz\n",
    "from uncertainty_toolbox.recalibration import iso_recal\n",
    "\n",
    "import bpnet\n",
    "from bpnet.datasets import StrandedProfile\n",
    "from bpnet.dataspecs import DataSpec, TaskSpec\n",
    "from bpnet.utils import create_tf_session\n",
    "from bpnet.utils import read_json\n",
    "from bpnet.seqmodel import SeqModel\n",
    "from bpnet.plot.evaluate import plot_loss, regression_eval\n",
    "\n",
    "from filter_instrument_candidates import filter_variants_by_score\n",
    "from in_silico_mutagenesis import compute_summary_statistics, generate_wt_mut_batches, write_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "output_dir = f'/home/ubuntu/dev/an1lam/deepmr/dat/res-bpnet-{timestamp}'\n",
    "model_base_dir = \"/home/ubuntu/dev/an1lam/deepmr/dat/res-bpnet-training-2022-01-29-22-58-12/output_ensemble\"\n",
    "factor_names = ['Oct4', 'Sox2', 'Nanog', 'Klf4']\n",
    "\n",
    "exposure_outcome_pairs = [\n",
    "    (exposure_name, outcome_name)\n",
    "    for exposure_name in factor_names\n",
    "    for outcome_name in factor_names\n",
    "    if exposure_name != outcome_name\n",
    "]\n",
    "\n",
    "results_fnames = [\n",
    "    f'{exposure_name}_{outcome_name}_effect_sizes.csv' for exposure_name, outcome_name in exposure_outcome_pairs\n",
    "]\n",
    "n_seqs = 2000\n",
    "n_reps = 5\n",
    "alphabet_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, model_base_dir, n_reps=5):\n",
    "        models = []\n",
    "        for i in range(n_reps):\n",
    "            models.append(SeqModel.from_mdir(os.path.join(model_base_dir, str(i))))\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, seqs):\n",
    "        preds = {}\n",
    "        for model in self.models:\n",
    "            model_preds = model.predict(seqs)\n",
    "            for key, preds_ in model_preds.items():\n",
    "                preds.setdefault(key, []).append(preds_.mean(-1))\n",
    "        return {k: np.stack(v) for k, v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(model_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_session(0)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {model_base_dir}/0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ensemble(model_base_dir, n_reps=2)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.18378,
     "end_time": "2019-08-01T09:53:08.162361",
     "exception": false,
     "start_time": "2019-08-01T09:53:07.978581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat {model_base_dir}/0/evaluation.valid.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028215,
     "end_time": "2019-08-01T09:53:08.235373",
     "exception": false,
     "start_time": "2019-08-01T09:53:08.207158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gin_config = read_json(os.path.join(model_base_dir, '0', 'config.gin.json'))\n",
    "gin_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSpec.load(os.path.join(model_base_dir, '0', 'dataspec.yml')) # remember to re-add 0\n",
    "tasks = list(ds.task_specs)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.047284,
     "end_time": "2019-08-01T09:53:08.352758",
     "exception": false,
     "start_time": "2019-08-01T09:53:08.305474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_valid = StrandedProfile(ds, \n",
    "                           incl_chromosomes=gin_config['bpnet_data.valid_chr'], \n",
    "                           peak_width=gin_config['bpnet_data.peak_width'],\n",
    "                           seq_width=gin_config['bpnet_data.seq_width'],\n",
    "                           inter\n",
    "                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.107385,
     "end_time": "2019-08-01T09:53:08.501413",
     "exception": false,
     "start_time": "2019-08-01T09:53:08.394028",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid = dl_valid.load_all(batch_size=256, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid['targets']['Oct4/counts'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re-)Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_recalibrators(model, features, dataset: dict, batch_size=256):\n",
    "    seqs = dataset['inputs']['seq']\n",
    "    targets = dataset['targets']\n",
    "    predictions = {f: np.zeros((seqs.shape[0], n_reps)) for f in features}\n",
    "    ys = {k: np.zeros(seqs.shape[0]) for k, v in dataset['targets'].items()}\n",
    "    for start_idx in range(0, len(seqs), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(seqs))\n",
    "        seq_batch = seqs[start_idx: end_idx]\n",
    "        p = model.predict(seq_batch)\n",
    "        if start_idx % (256 * 10) == 0:\n",
    "            print(start_idx)\n",
    "        for f in features:\n",
    "            predictions[f][start_idx: end_idx, :] = p[f].T\n",
    "            ys[f][start_idx: end_idx] = targets[f][start_idx: end_idx, :].mean(axis=-1)\n",
    "\n",
    "    pred_means = {}\n",
    "    pred_stds = {}\n",
    "    for f in features:\n",
    "        pred_means[f] = np.mean(predictions[f], axis=1).squeeze()\n",
    "        pred_stds[f] = np.std(predictions[f], axis=1).squeeze()\n",
    "\n",
    "    recal_models = {}\n",
    "    for f in features:\n",
    "        y = ys[f]\n",
    "        pred_mean, pred_std = pred_means[f], pred_stds[f]\n",
    "        exp_props, obs_props = get_proportion_lists_vectorized(pred_mean, pred_std, y)\n",
    "        recal_model = iso_recal(exp_props, obs_props)\n",
    "        recal_models[f] = recal_model\n",
    "    return recal_models\n",
    "\n",
    "def recal_predict(recalibrators, preds, features):\n",
    "    pred_means = {}\n",
    "    pred_stds = {}\n",
    "    for f in features:\n",
    "        pred_means[f] = np.mean(preds[f], axis=0).squeeze()\n",
    "        pred_stds[f] = np.std(preds[f], axis=0).squeeze()\n",
    "    recal_preds = {k: np.zeros_like(v) for k, v in preds.items()}\n",
    "    for f in features:\n",
    "        pred_dist = stats.norm(loc=pred_means[f], scale=pred_stds[f])\n",
    "        for c in range(preds[f].shape[0]):\n",
    "            recal_model = recalibrators[f]\n",
    "            orig_preds = preds[f][c, :]\n",
    "            orig_quantiles = pred_dist.cdf(orig_preds)\n",
    "            recal_quantiles = recal_model.predict(orig_quantiles)\n",
    "            recal_preds[f][c] = pred_dist.ppf(recal_quantiles)\n",
    "    return recal_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and in-silico mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'{factor_name}/counts' for factor_name in factor_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['inputs']['seq'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_records = []\n",
    "valid_range_meta = valid['metadata']['range']\n",
    "it = zip(valid['inputs']['seq'], valid_range_meta['start'], valid_range_meta['end'], valid_range_meta['strand'])\n",
    "for seq, start, end, strand in it:\n",
    "    if ((seq == 0.0) | (seq == 1.0)).all():\n",
    "        valid_records.append({\n",
    "            \"seq\": seq,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"strand\": strand,\n",
    "        })\n",
    "valid_ranges = pd.DataFrame.from_records(valid_records)\n",
    "valid_seqs = valid_df.seq.values\n",
    "valid_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idxs = np.arange(len(valid_seqs))\n",
    "np.random.shuffle(idxs)\n",
    "sample_seqs = valid_seqs[idxs[:n_seqs]]\n",
    "sample_ranges = valid_ranges.iloc[idxs[:n_seqs]]\n",
    "sample_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_df = pd.read_csv('/home/ubuntu/motif-instances.bed', sep='\\t', header=None)\n",
    "mfi_df.columns = [\"chrom\", \"start\", \"end\", \"tf\", \"match-score\", \"strand\", \"contrib-score\", \"log-odds-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mfi_df = mfi_df.query('chrom in [\"chr2\", \"chr3\", \"chr4\"]').sort_values(by=['chrom', 'start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in valid_ranges.iterrows():\n",
    "    mfi_rows = valid_mfi_df.query(\n",
    "        f\"start >= {row.sequence_start} and end <= {row.sequence_end} and chrom == '{row.chrom}'\"\n",
    "    )\n",
    "    # mfi_rows = mfi_rows.query(f\"strand == '{row.strand}'\")\n",
    "    for _, mfi_row in mfi_rows.iterrows():\n",
    "        valid_ranges.loc[idx, f\"{mfi_row.tf}_start\"] = mfi_row.start\n",
    "        valid_ranges.loc[idx, f\"{mfi_row.tf}_end\"] = mfi_row.end  \n",
    "        valid_ranges.loc[idx, f\"{mfi_row.tf}_match_score\"] = mfi_row[\"match-score\"]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(start1, start2, end1, end2):\n",
    "    if end1 < start2:\n",
    "        return start2 - end1\n",
    "    elif end2 < start1:\n",
    "        return start1 - end2\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid positions: {start1}-{end1}, {start2}-{end2}\")\n",
    "\n",
    "for exposure, outcome in exposure_outcome_pairs:\n",
    "    distance_column_name = f\"{exposure}_{outcome}_distance\"\n",
    "    assert f\"{exposure}_start\" in valid_ranges.columns and f\"{outcome}_start\" in valid_ranges.columns\n",
    "    columns = (f\"{exposure}_start\", f\"{outcome}_start\", f\"{exposure}_end\", f\"{outcome}_end\")\n",
    "    valid_ranges[distance_column_name] = valid_ranges[columns].apply(\n",
    "        lambda row: get_distance(*[row[c] for c in columns]),\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['inputs']['seq'].shape, valid['targets'][cols[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_models = fit_recalibrators(model, cols, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seqs = sample_seqs.shape\n",
    "preds = {}\n",
    "recal_preds = {}\n",
    "for seq in sample_seqs:\n",
    "    muts = generate_wt_mut_batches(seq.T, seq.shape[0] * seq.shape[1]).squeeze()\n",
    "    preds_ = model.predict(muts.transpose(0, 2, 1))\n",
    "    recal_preds_ = recal_predict(recal_models, preds_, cols)\n",
    "    for key, value in preds_.items():\n",
    "        if key in cols:\n",
    "            preds.setdefault(key, []).append(preds_[key])\n",
    "            recal_preds.setdefault(key, []).append(recal_preds_[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(preds['Oct4/counts']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exposure_outcome_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = sample_seqs.transpose(0, 2, 1)\n",
    "\n",
    "for exposure, outcome in exposure_outcome_pairs[6:]:\n",
    "    print(exposure_col, outcome_col)\n",
    "    exposure_col = f'{exposure}/counts'\n",
    "    outcome_col = f'{outcome}/counts'\n",
    "    \n",
    "    formatted_preds = np.stack((preds[exposure_col], preds[outcome_col]))\n",
    "    n_features, n_seqs, n_reps, n_variants = formatted_preds.shape\n",
    "    formatted_preds = formatted_preds.transpose(2, 1, 3, 0)\n",
    "    formatted_preds = formatted_preds.reshape(n_reps, n_seqs, alphabet_size, -1, n_features)\n",
    "    motif_distances = valid_ranges[f\"{exposure}_{outcome}_distance\"].values\n",
    "    means, mean_diffs, stderrs = compute_summary_statistics(formatted_preds, seqs)\n",
    "    assert len(motif_distances) == mean_diffs.shape[0]\n",
    "    \n",
    "    sig_var_idxs = filter_variants_by_score(mean_diffs[:, :, :, 0], z_threshold=3.0)\n",
    "    print(\n",
    "        \"Reduced number of instruments down from %d to %d (%.2f %%)\"\n",
    "        % (\n",
    "            np.prod(mean_diffs.shape),\n",
    "            len(np.nonzero(sig_var_idxs)[0]),\n",
    "            float(len(np.nonzero(sig_var_idxs)[0]) / np.prod(mean_diffs.shape)) * 100,\n",
    "        )\n",
    "    )\n",
    "    print(sig_var_idxs.shape)\n",
    "\n",
    "    results_fname = f'{exposure}_{outcome}_effect_sizes_v2.csv'\n",
    "    results_fpath = os.path.join(output_dir, results_fname)\n",
    "    write_results(results_fpath, mean_diffs, stderrs,  sig_idxs=sig_var_idxs, motif_distance=motif_distances)\n",
    "    print(results_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diffs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmr-bpnet3",
   "language": "python",
   "name": "deepmr-bpnet3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
