{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import simdna\n",
    "from simdna import synthetic\n",
    "import torch\n",
    "\n",
    "from pyx.one_hot import one_hot\n",
    "from tf_coop_model import CountsRegressor, IterablePandasDataset\n",
    "from tf_coop_model import anscombe_transform, run_one_epoch, pearson_r, spearman_rho, rsquared\n",
    "from tf_coop_simulation import background_frequency, simulate_oracle_predictions\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model & Load Weights\n",
    "This step assumes we've trained a counts regression model and have its weights stored in a .pt[h] file somewhere accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 3\n",
    "n_dense_layers = 3\n",
    "n_outputs = 2\n",
    "sequence_length = 100\n",
    "filters = 15\n",
    "filter_width = 7\n",
    "dense_layer_width = 30\n",
    "\n",
    "no_variants_weights_fpath = '../dat/sim_conf/cnn_counts_predictor_no_variants.pt'\n",
    "variants_weights_fpath = '../dat/sim_conf/cnn_counts_predictor_with_variants.pt'\n",
    "\n",
    "test_data_fpath = '../dat/sim_conf/test_labels.csv'\n",
    "test_variants_data_fpath = '../dat/sim_conf/test_variant_labels.csv'\n",
    "raw_simulation_data_fpath = '../dat/sim_conf/test_sequences.simdata'\n",
    "\n",
    "exposure_motif = \"GATA_disc1\"\n",
    "outcome_motif = \"TAL1_known1\"\n",
    "\n",
    "sequences_col = \"sequences\"\n",
    "label_cols = [\"labels_exp\", \"labels_out\"]\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CountsRegressor:\n\tMissing key(s) in state_dict: \"conv_layers.6.weight\", \"conv_layers.6.bias\", \"conv_layers.7.weight\", \"conv_layers.7.bias\", \"conv_layers.7.running_mean\", \"conv_layers.7.running_var\", \"dense_layers.3.weight\", \"dense_layers.3.bias\", \"dense_layers.5.weight\", \"dense_layers.5.bias\". \n\tsize mismatch for dense_layers.1.weight: copying a param with shape torch.Size([30, 1320]) from checkpoint, the shape in current model is torch.Size([30, 1230]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-446808a3e2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdense_layer_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mvariants_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariants_weights_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mvariants_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepmr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CountsRegressor:\n\tMissing key(s) in state_dict: \"conv_layers.6.weight\", \"conv_layers.6.bias\", \"conv_layers.7.weight\", \"conv_layers.7.bias\", \"conv_layers.7.running_mean\", \"conv_layers.7.running_var\", \"dense_layers.3.weight\", \"dense_layers.3.bias\", \"dense_layers.5.weight\", \"dense_layers.5.bias\". \n\tsize mismatch for dense_layers.1.weight: copying a param with shape torch.Size([30, 1320]) from checkpoint, the shape in current model is torch.Size([30, 1230])."
     ]
    }
   ],
   "source": [
    "variants_model = CountsRegressor(n_conv_layers,\n",
    "    n_dense_layers,\n",
    "    n_outputs,\n",
    "    sequence_length,\n",
    "    filters,\n",
    "    filter_width,\n",
    "    dense_layer_width\n",
    ")\n",
    "variants_model.load_state_dict(torch.load(variants_weights_fpath))\n",
    "variants_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_variants_model = CountsRegressor(n_conv_layers,\n",
    "    n_dense_layers,\n",
    "    n_outputs,\n",
    "    sequence_length,\n",
    "    filters,\n",
    "    filter_width,\n",
    "    dense_layer_width\n",
    ")\n",
    "no_variants_model.load_state_dict(torch.load(no_variants_weights_fpath))\n",
    "no_variants_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data & Generate Predictions\n",
    "Now we're going to load test data to get some basic metrics about how well our model performs. We'll later use these numbers to test whether the model maintains its performance when predicting counts for test set variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_fpath)\n",
    "\n",
    "test_dataset = IterablePandasDataset(\n",
    "    test_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    "    y_transform=anscombe_transform,\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_predictions, _, variants_metrics = run_one_epoch(\n",
    "    variants_model, test_data_loader, None, training=False, metrics_config={\n",
    "        \"spearman-rho\": spearman_rho,\n",
    "        \"r-squared\": rsquared,\n",
    "        \"pearson-r\": pearson_r,\n",
    "    }\n",
    ")\n",
    "no_variants_predictions, _, no_variants_metrics = run_one_epoch(\n",
    "    no_variants_model, test_data_loader, None, training=False, metrics_config={\n",
    "        \"spearman-rho\": spearman_rho,\n",
    "        \"r-squared\": rsquared,\n",
    "        \"pearson-r\": pearson_r,\n",
    "    }\n",
    ")\n",
    "print(\"Variants Model Metrics: \", variants_metrics)\n",
    "print(\"No Variants Model Metrics: \", no_variants_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_exp_labels = [l[0] for _, l in test_dataset]\n",
    "test_out_labels = np.array([l[1] for _, l in test_dataset])\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 8), constrained_layout=True)\n",
    "\n",
    "fig.suptitle(\"Wild Type Predictions vs. True Counts\")\n",
    "\n",
    "axs[0, 0].scatter(test_exp_labels, np.array(variants_predictions)[:, 0], alpha=0.05)\n",
    "axs[0, 0].set_title(\"Exposure Predictions (Variants Model)\")\n",
    "axs[0, 0].set_xlabel(\"Actual exposure counts\")\n",
    "axs[0, 0].set_ylabel(\"Predicted exposure counts\")\n",
    "\n",
    "axs[0, 1].scatter(test_exp_labels, np.array(no_variants_predictions)[:, 0], alpha=0.05)\n",
    "axs[0, 1].set_title(\"Exposure Predictions (No Variants Model)\")\n",
    "axs[0, 1].set_xlabel(\"Actual exposure counts\")\n",
    "axs[0, 1].set_ylabel(\"Predicted exposure counts\")\n",
    "\n",
    "axs[1, 0].scatter(test_exp_labels, np.array(variants_predictions)[:, 1], alpha=0.05)\n",
    "axs[1, 0].set_title(\"Outcome Predictions (Variants Model)\")\n",
    "axs[1, 0].set_xlabel(\"Actual outcome counts\")\n",
    "axs[1, 0].set_ylabel(\"Predicted outcome counts\")\n",
    "\n",
    "axs[1, 1].scatter(test_exp_labels, np.array(no_variants_predictions)[:, 1], alpha=0.05)\n",
    "axs[1, 1].set_title(\"Outcome Predictions (No Variants Model)\")\n",
    "axs[1, 1].set_xlabel(\"Actual outcome counts\")\n",
    "axs[1, 1].set_ylabel(\"Predicted outcome counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exp_labels = [l[0] for _, l in test_dataset]\n",
    "test_out_labels = np.array([l[1] for _, l in test_dataset])\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(14, 8), constrained_layout=True)\n",
    "\n",
    "fig.suptitle(\"Wild Type Predictions vs. True Counts\")\n",
    "\n",
    "axs.scatter(np.array(variants_predictions)[:, 0], np.array(variants_predictions)[:, 1], alpha=0.3)\n",
    "axs.set_title(\"Exposure Predictions (Variants Model)\")\n",
    "axs.set_xlabel(\"Predicted exposure counts\")\n",
    "axs.set_ylabel(\"Predicted outcome counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant effect prediction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_fpath)\n",
    "test_variants_df = pd.read_csv(test_variants_data_fpath)\n",
    "filtered_test_variants_df = test_variants_df[\n",
    "    (test_variants_df['has_both'] == 1)\n",
    "].reset_index()\n",
    "\n",
    "original_variant_rows = test_df.iloc[filtered_test_variants_df['original_index'], :].reset_index().copy()\n",
    "original_variant_rows = original_variant_rows.rename(\n",
    "    columns={'labels_exp': 'original_labels_exp', 'labels_out': 'original_labels_out'}\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    variant, wild_type = filtered_test_variants_df.sequences.values[i], original_variant_rows.sequences.values[i]\n",
    "    assert editdistance.eval(variant, wild_type) in [1, 2], editdistance.eval(variant, wild_type)\n",
    "\n",
    "original_variant_rows = original_variant_rows.drop(columns=[\"sequences\"])\n",
    "variants_df = pd.concat((filtered_test_variants_df, original_variant_rows), axis=1)\n",
    "\n",
    "variants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_test_dataset = IterablePandasDataset(\n",
    "    variants_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot, y_transform=anscombe_transform\n",
    ")\n",
    "variants_test_data_loader = torch.utils.data.DataLoader(\n",
    "    variants_test_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_variant_predictions, _, variants_variant_metrics = run_one_epoch(\n",
    "    variants_model, variants_test_data_loader, None, training=False, metrics_config={\n",
    "        \"spearman-rho\": spearman_rho,\n",
    "        \"r-squared\": rsquared,\n",
    "        \"pearson-r\": pearson_r,\n",
    "    }\n",
    ")\n",
    "no_variants_variant_predictions, losses, no_variants_variant_metrics = run_one_epoch(\n",
    "    no_variants_model, variants_test_data_loader, None, training=False, metrics_config={\n",
    "        \"spearman-rho\": spearman_rho,\n",
    "        \"r-squared\": rsquared,\n",
    "        \"pearson-r\": pearson_r,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exp_labels = np.array([l[0] for _, l in variants_test_dataset])\n",
    "test_out_labels = np.array([l[1] for _, l in variants_test_dataset])\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "fig.suptitle(\"Variant Predictions vs. True Counts\")\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "ax = axs[0, 0]\n",
    "counts, pred_counts = test_exp_labels, np.array(variants_variant_predictions)[:, 0]\n",
    "ax.scatter(counts, pred_counts, alpha=0.1)\n",
    "ax.set_title(\"Exposure Counts (Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Exposure Count\")\n",
    "ax.set_ylabel(\"Predicted Exposure Count\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(counts, pred_counts)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(counts, pred_counts)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[0, 1]\n",
    "counts, pred_counts = test_exp_labels, np.array(no_variants_variant_predictions)[:, 0]\n",
    "ax.scatter(counts, pred_counts, alpha=0.1)\n",
    "ax.set_title(\"Exposure Counts (No Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Exposure Count\")\n",
    "ax.set_ylabel(\"Predicted Exposure Count\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(counts, pred_counts)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(counts, pred_counts)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[1, 0]\n",
    "counts, pred_counts = test_out_labels, np.array(variants_variant_predictions)[:, 1]\n",
    "ax.scatter(counts, pred_counts, alpha=0.1)\n",
    "ax.set_title(\"Outcome Variants (Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Outcome Variant\")\n",
    "ax.set_ylabel(\"Predicted Outcome Variant\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(counts, pred_counts)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(counts, pred_counts)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[1, 1]\n",
    "counts, pred_counts = test_out_labels, np.array(no_variants_variant_predictions)[:, 1]\n",
    "ax.scatter(counts, pred_counts, alpha=0.1)\n",
    "ax.set_title(\"Outcome Variants (No Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Outcome Variant\")\n",
    "ax.set_ylabel(\"Predicted Outcome Variant\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(counts, pred_counts)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(counts, pred_counts)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_exp_variant_effects = (\n",
    "    anscombe_transform(variants_df['labels_exp']) - anscombe_transform(variants_df['original_labels_exp'])\n",
    ")\n",
    "real_out_variant_effects = (\n",
    "    anscombe_transform(variants_df['labels_out']) - anscombe_transform(variants_df['original_labels_out'])\n",
    ")\n",
    "original_variants_variant_predictions = [variants_predictions[i] for i in variants_df['original_index']]\n",
    "variants_predicted_variant_effects = (\n",
    "    np.array(variants_variant_predictions) - np.array(original_variants_variant_predictions)\n",
    ")\n",
    "\n",
    "original_no_variants_variant_predictions = [no_variants_predictions[i] for i in variants_df['original_index']]\n",
    "no_variants_predicted_variant_effects = (\n",
    "    np.array(no_variants_variant_predictions) - np.array(original_no_variants_variant_predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "fig.suptitle(\"Variant Effect Predictions vs. True Variant Effects\")\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "ax = axs[0, 0]\n",
    "veffs, pred_veffs = real_exp_variant_effects, variants_predicted_variant_effects[:, 0]\n",
    "ax.scatter(veffs, pred_veffs, alpha=0.1)\n",
    "ax.set_title(\"Exposure Variant Effects (Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Exposure Variant Effect\")\n",
    "ax.set_ylabel(\"Predicted Exposure Variant Effect\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(veffs, pred_veffs)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(veffs, pred_veffs)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[0, 1]\n",
    "veffs, pred_veffs = real_exp_variant_effects, no_variants_predicted_variant_effects[:, 0]\n",
    "ax.scatter(veffs, pred_veffs, alpha=0.1)\n",
    "ax.set_title(\"Exposure Variant Effects (No Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Exposure Variant Effect\")\n",
    "ax.set_ylabel(\"Predicted Exposure Variant Effect\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(veffs, pred_veffs)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(veffs, pred_veffs)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[1, 0]\n",
    "veffs, pred_veffs = real_out_variant_effects, variants_predicted_variant_effects[:, 1]\n",
    "ax.scatter(veffs, pred_veffs, alpha=0.1)\n",
    "ax.set_title(\"Outcome Variant Effects (Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Outcome Variant Effect\")\n",
    "ax.set_ylabel(\"Predicted Outcome Variant Effect\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(veffs, pred_veffs)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(veffs, pred_veffs)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")\n",
    "\n",
    "ax = axs[1, 1]\n",
    "veffs, pred_veffs = real_out_variant_effects, no_variants_predicted_variant_effects[:, 1]\n",
    "ax.scatter(veffs, pred_veffs, alpha=0.1)\n",
    "ax.set_title(\"Outcome Variant Effects (No Variants Model)\")\n",
    "ax.set_xlabel(\"Actual Outcome Variant Effect\")\n",
    "ax.set_ylabel(\"Predicted Outcome Variant Effect\")\n",
    "metrics_str = '\\n'.join((\n",
    "    r'$ R^2 = %.3f $' % (rsquared(veffs, pred_veffs)),\n",
    "    r'$ \\rho = %.3f $' % (spearman_rho(veffs, pred_veffs)),\n",
    "))\n",
    "ax.text(\n",
    "    0.05, 0.95, metrics_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
