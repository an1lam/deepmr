{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kipoi\n",
    "# !pip install kipoiseq\n",
    "# !pip install pybedtools\n",
    "# !pip uninstall -y kipoi_veff\n",
    "# !pip install git+https://github.com/an1lam/kipoi-veff\n",
    "# !pip install pyvcf\n",
    "import kipoi\n",
    "from kipoi_interpret.importance_scores.ism import Mutation\n",
    "from kipoiseq.dataloaders import SeqIntervalDl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/project/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.14.0\n",
      "torch version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "import torch\n",
    "print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = kipoi.list_models()\n",
    "# deepsea_models = df[df.model.str.contains(\"DeepSEA\")]\n",
    "# deepsea_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/jupyter/.kipoi/models/DeepSEA/variantEffects/downloaded/model_files/weights/35956ab9c28960b5a3693f470fe980c1\n"
     ]
    }
   ],
   "source": [
    "deepsea = kipoi.get_model(\"DeepSEA/variantEffects\", source=\"kipoi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DNA sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:03<00:00,  8.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = SeqIntervalDl(\"../dat/ChIPseq.A549.CTCF.1000.random.narrowPeak.gz\", \"../dat/hg19.fa\", auto_resize_len=1000)\n",
    "data = dl.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 4, 1, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = np.expand_dims(data['inputs'].transpose(0, 2, 1), 2).astype(np.float32)\n",
    "seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking the model\n",
    "This section is focused on tweaking DeepSEA's model to use dropout when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReCodeAlphabet()\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (1): Threshold(threshold=0, value=1e-06)\n",
       "    (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (5): Threshold(threshold=0, value=1e-06)\n",
       "    (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (9): Threshold(threshold=0, value=1e-06)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Lambda()\n",
       "    (12): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=50880, out_features=925, bias=True)\n",
       "    )\n",
       "    (13): Threshold(threshold=0, value=1e-06)\n",
       "    (14): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=925, out_features=919, bias=True)\n",
       "    )\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsea.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def apply_dropout(m):\n",
    "    if type(m) == nn.Dropout:\n",
    "        m.train()\n",
    "        \n",
    "def unapply_dropout(m):\n",
    "    if type(m) == nn.Dropout:\n",
    "        m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying dropout is being applied\n",
    "We can verify or at least get reasonable certainty that dropout's being applied by running 10 predictions on the same sequence and then seeing that the predicted binding probs differ. First, we show that the predictions stay the same if dropout is off.\n",
    "\n",
    "Then, we turn on dropout and show that they start to vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = deepsea.pipeline.predict_example()\n",
    "for i in range(3):\n",
    "    print(f\"First few preds ({i+1}/3): \", deepsea.pipeline.predict_example()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsea.model.eval()\n",
    "deepsea.model = deepsea.model.apply(apply_dropout)\n",
    "preds = deepsea.pipeline.predict_example()\n",
    "for i in range(3):\n",
    "    print(f\"First few preds ({i+1}/3): \", deepsea.pipeline.predict_example()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and in-silico mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(52, 'A549_DNase_None'), (720, 'A549_CTCF_None'), (763, 'A549_CTCF_None')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHROM_ACC_COL = 'A549_DNase_None'\n",
    "TF_COL = 'A549_CTCF_None'\n",
    "relevant_cols = sorted([(i, label)\n",
    "                        for i, label in enumerate(deepsea.schema.targets.column_labels)\n",
    "                        if label in [CHROM_ACC_COL, TF_COL]])\n",
    "\n",
    "def output_sel_fn(result):\n",
    "    return np.array([result[col_idx] for col_idx, _ in relevant_cols])\n",
    "\n",
    "relevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6371d34ae15f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepsea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_sel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mism_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/kipoi_interpret/importance_scores/ism.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, input_batch)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 mult_set = set_model_input(mult_set, numpy_collate(alt_batch),\n\u001b[1;32m    148\u001b[0m                                            input_id=model_input_id)\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0malt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmult_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0malt_sample_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0malt_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_sample_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/kipoi/model.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_run_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumpy_to_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/kipoi/model.py\u001b[0m in \u001b[0;36mpred_to_np\u001b[0;34m(self, pred)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;31m# convert results back to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mpred_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_var_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/kipoi/model.py\u001b[0m in \u001b[0;36m_torch_var_to_numpy\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_torch_var_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ism = Mutation(deepsea, \"seq\", scores=['ref', 'diff'], output_sel_fn=output_sel_fn)\n",
    "ism_score = np.array(ism.score(seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(ism_score).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((2, 3))\n",
    "def sanitize_scores(scores):\n",
    "    orig_shape = scores.shape\n",
    "    sanitized_scores = np.ndarray((*orig_shape, 2, 3), dtype=scores.dtype)\n",
    "    flattened_scores = scores.reshape(-1)\n",
    "    \n",
    "    for i, score in enumerate(flattened_scores):\n",
    "        idx = np.unravel_index(i, orig_shape)\n",
    "        if score is None: sanitized_scores[idx] = zeros\n",
    "        else: sanitized_scores[idx] = np.array(score)\n",
    "    return sanitized_scores\n",
    "\n",
    "sanitized_scores = sanitize_scores(np.squeeze(ism_score))\n",
    "ctcf_original_preds = sanitized_scores[:, :, :, 0, 1]\n",
    "ctcf_pred_diffs = sanitized_scores[:, :, :, 1, 1]\n",
    "dnase_original_preds = sanitized_scores[:, :, :, 0, 0]\n",
    "dnase_pred_diff = sanitized_scores[:, :, :, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "log_uniform_prop = math.log(.05/(1-.05))\n",
    "def compute_normalized_prob(prob, train_prob):\n",
    "    denom = 1+np.exp(-(np.log(prob/(1-prob))+log_uniform_prop-np.log(train_prob/(1-train_prob))))\n",
    "    return 1 / denom\n",
    "\n",
    "# Ratios and normalization formula drawn from here: http://deepsea.princeton.edu/media/help/posproportion.txt\n",
    "tf_compute_normalized_prob = lambda prob: compute_normalized_prob(prob, .020029)\n",
    "# ENCODE\tA549\tDNase\tNone\t0.048136\n",
    "chrom_acc_normalized_prob = lambda prob: compute_normalized_prob(prob, 0.048136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TO_NT = 'ACGT'\n",
    "\n",
    "def _convert_to_mutation(pos_nt_pair):\n",
    "    return \"%d%s\" % (pos_nt_pair[1], IDX_TO_NT[pos_nt_pair[0]])\n",
    "\n",
    "def find_best_mutation(mutation_map, sign=1):\n",
    "    seq_len = mutation_map.shape[1]\n",
    "    best_mute = None\n",
    "    best_mute_effect = 0\n",
    "    second_best_mute = None\n",
    "    second_best_mute_effect = 0\n",
    "    for seq_idx in range(seq_len):  # iterate over sequence\n",
    "        best_out_of_nts_mute = None\n",
    "        best_out_of_nts_mute_effect = 0 \n",
    "        for nt_idx in range(4):  # iterate over nucleotides\n",
    "            current_effect = mutation_map[nt_idx, seq_idx]\n",
    "            \n",
    "            if sign * current_effect > sign * best_out_of_nts_mute_effect:\n",
    "                best_out_of_nts_mute_effect = current_effect\n",
    "                best_out_of_nts_mute = (nt_idx, seq_idx)\n",
    "\n",
    "        # TODO(Stephen): the right way to do this is to have a heap, squish the 2D array into a 1D\n",
    "        # array of (effect, (seq_idx, nt_idx)) tuples and then take the top-k from the heap, but\n",
    "        # I'm too lazy to do this right now.\n",
    "        if sign * best_out_of_nts_mute_effect > (sign * best_mute_effect):\n",
    "            best_mute_effect = best_out_of_nts_mute_effect\n",
    "            best_mute = best_out_of_nts_mute\n",
    "        elif sign * best_out_of_nts_mute_effect > (sign * second_best_mute_effect):\n",
    "            second_best_mute_effect = best_out_of_nts_mute_effect\n",
    "            second_best_mute = best_out_of_nts_mute \n",
    "    print(best_mute, best_mute_effect, second_best_mute, second_best_mute_effect)\n",
    "    return [best_mute, second_best_mute]\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "mut_effects_fpath = \"../dat/mut_effects_1.csv\"\n",
    "with open(mut_effects_fpath, 'w', newline=\"\") as out_file:\n",
    "    fieldnames = [\n",
    "        \"initial X prediction\",\n",
    "        \"new X prediction\",\n",
    "        \"initial Y prediction\",\n",
    "        \"new Y prediction\",\n",
    "        \"mutation\",\n",
    "    ]\n",
    "    writer = csv.DictWriter(out_file, delimiter=\",\", fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for i, ctcf_pred_diff in enumerate(ctcf_pred_diffs):\n",
    "        best_mut_idx, best_mut_effect = find_best_mutation(ctcf_pred_diff, sign=-1)\n",
    "        nt_idx, seq_idx = best_mut_idx\n",
    "        ctcf_original_pred = ctcf_original_preds[i][nt_idx, seq_idx]\n",
    "        ctcf_new_pred = ctcf_original_pred + ctcf_pred_diff[nt_idx, seq_idx]\n",
    "        dnase_original_pred = dnase_original_preds[i][nt_idx, seq_idx]\n",
    "        dnase_pred_diff = dnase_pred_diffs[i][nt_idx, seq_idx]\n",
    "        dnase_new_prd = dnase_original_pred + dnase_pred_diff\n",
    "        writer.writerow(\n",
    "            {\n",
    "                \"initial X prediction\": ctcf_original_pred,\n",
    "                \"new X prediction\": ctcf_new_pred,\n",
    "                \"initial Y prediction\": dnase_original_pred,\n",
    "                \"new Y prediction\": dnase_new_pred,\n",
    "                \"mutation\": _convert_to_mutation(best_mut_idx),\n",
    "            }\n",
    "        )\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
