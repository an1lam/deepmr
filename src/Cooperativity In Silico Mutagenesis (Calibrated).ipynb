{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import simdna\n",
    "from simdna import synthetic\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "import uncertainty_toolbox.data as udata\n",
    "import uncertainty_toolbox.metrics as umetrics\n",
    "from uncertainty_toolbox.metrics_calibration import (\n",
    "    get_proportion_lists_vectorized,\n",
    ")\n",
    "import uncertainty_toolbox.viz as uviz\n",
    "from uncertainty_toolbox.recalibration import iso_recal\n",
    "\n",
    "from ensemble import Ensemble, CalibratedRegressionEnsemble\n",
    "from utils import one_hot_decode\n",
    "from in_silico_mutagenesis import compute_summary_statistics, generate_wt_mut_batches, write_results\n",
    "from pyx.one_hot import one_hot\n",
    "from tf_coop_model import CountsRegressor, IterablePandasDataset\n",
    "from tf_coop_model import anscombe_transform, run_one_epoch, spearman_rho, pearson_r\n",
    "from tf_coop_simulation import background_frequency\n",
    "from tf_coop_simulation import simulate_counts, simulate_oracle_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model & Load Weights\n",
    "This step assumes we've trained a counts regression model and have its weights stored in a .pt[h] file somewhere accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 3\n",
    "n_dense_layers = 3\n",
    "n_outputs = 2\n",
    "sequence_length = 100\n",
    "filters = 15\n",
    "filter_width = 7\n",
    "dense_layer_width = 30\n",
    "\n",
    "data_dir = '../dat/sim'\n",
    "weights_dir = os.path.join(data_dir, 'ensemble')\n",
    "weights_fname = 'cnn_counts_predictor_with_variants.pt'\n",
    "test_data_fpath = os.path.join(data_dir, 'test_labels.csv')\n",
    "raw_simulation_data_fpath = os.path.join(data_dir, 'test_sequences.simdata')\n",
    "mutagenesis_results_dir = os.path.join(data_dir, 'res')\n",
    "\n",
    "os.makedirs(mutagenesis_results_dir, exist_ok=True)\n",
    "\n",
    "sequences_col = \"sequences\"\n",
    "label_cols = [\"labels_exp\", \"labels_out\"]\n",
    "batch_size = 1000\n",
    "n_samples = 10\n",
    "\n",
    "includes_confounder = False\n",
    "exposure_motif = \"GATA_disc1\"\n",
    "outcome_motif = \"TAL1_known1\"\n",
    "confounder_motif = \"SOX2_1\" if includes_confounder else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8c49da1a20>"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_fpath)\n",
    "test_dataset = IterablePandasDataset(\n",
    "    test_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    "    y_transform=anscombe_transform\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_conv_layers\": n_conv_layers,\n",
    "    \"n_dense_layers\": n_dense_layers,\n",
    "    \"n_outputs\": n_outputs,\n",
    "    \"sequence_length\": sequence_length,\n",
    "    \"filters\": filters,\n",
    "    \"filter_width\": filter_width,\n",
    "    \"dense_layer_width\": dense_layer_width\n",
    "}\n",
    "ensemble_model = Ensemble(weights_dir, \"cnn_counts_predictor.pt\", params, n_reps=10)\n",
    "calibrated_ensemble_model = CalibratedRegressionEnsemble(ensemble_model, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data & Generate Predictions\n",
    "Now we're going to load test data to get some basic metrics about how well our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Deep MR\n",
    "In Shrikumar et al, all effects are computed in raw counts space. Here, for purposes of making our result relevant to Deep MR, we compute interaction effects in both Anscombe-transformed space and raw counts space but focus on the validity of the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_df = test_df[(test_df['has_exposure'] == 1) & (test_df['has_outcome'] == 1)]\n",
    "exposure_motif_df = test_df[(test_df['has_exposure'] == 1) & (test_df['has_outcome'] == 0)]\n",
    "outcome_motif_df = test_df[(test_df['has_exposure'] == 0) & (test_df['has_outcome'] == 1)]\n",
    "neither_motif_df = test_df[\n",
    "    (test_df['has_exposure'] == 0) & (test_df['has_outcome'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2499, 2514, 2460, 2527)"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_motifs_df), len(exposure_motif_df), len(outcome_motif_df), len(neither_motif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_dataset = IterablePandasDataset(\n",
    "    both_motifs_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    "    y_transform=anscombe_transform\n",
    ")\n",
    "both_motifs_data_loader = torch.utils.data.DataLoader(\n",
    "    both_motifs_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_and_predict(model, sample_dataset, predictions_key = 'recal_predictions'):\n",
    "    preds = {}\n",
    "    all_muts = []\n",
    "    for seq, label in tqdm(sample_dataset):\n",
    "        muts = generate_wt_mut_batches(seq, seq.shape[0] * seq.shape[1]).squeeze()\n",
    "        muts = muts.transpose(0, 1, 2)\n",
    "        muts = torch.from_numpy(muts)\n",
    "        label = torch.from_numpy(label)\n",
    "        outputs = model.predict(muts)\n",
    "        preds_np = outputs[predictions_key]\n",
    "        exposure_preds = preds_np[:, :, 0]\n",
    "        outcome_preds = preds_np[:, :, 1]\n",
    "        preds.setdefault('exposure', []).append(exposure_preds)\n",
    "        preds.setdefault('outcome', []).append(outcome_preds)\n",
    "        all_muts.append(muts.detach().cpu().numpy())\n",
    "    return all_muts, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both_motifs_sample_dataset, _ = torch.utils.data.random_split(\n",
    "#     both_motifs_dataset, (n_samples, len(both_motifs_dataset) - n_samples)\n",
    "# )\n",
    "both_motifs_sample_dataset = both_motifs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286ea7a35476451798af011ab7b4ad5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2499.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "muts, recal_predictions = mutate_and_predict(\n",
    "    calibrated_ensemble_model, both_motifs_sample_dataset\n",
    ")\n",
    "muts, uncal_predictions = mutate_and_predict(\n",
    "    calibrated_ensemble_model, both_motifs_sample_dataset, predictions_key = 'predictions'\n",
    ")\n",
    "sample_seqs = np.array([seq for seq, label in both_motifs_sample_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exposure_col = \"exposure\"\n",
    "outcome_col = \"outcome\"\n",
    "\n",
    "formatted_preds = np.stack((recal_predictions[exposure_col], recal_predictions[outcome_col]))\n",
    "n_features, n_seqs, n_reps, n_variants = formatted_preds.shape\n",
    "formatted_preds = formatted_preds.transpose(2, 1, 3, 0)\n",
    "formatted_preds = formatted_preds.reshape(n_reps, n_seqs, 4, -1, n_features)\n",
    "\n",
    "means, mean_diffs, stderrs = compute_summary_statistics(formatted_preds, np.array(sample_seqs))\n",
    "\n",
    "np.save(os.path.join(mutagenesis_results_dir, \"GATA_TAL1_means_calibrated_v2.npy\"), means)\n",
    "np.save(os.path.join(mutagenesis_results_dir, \"GATA_TAL1_stderrs_calibrated_v2.npy\"), stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_col = \"exposure\"\n",
    "outcome_col = \"outcome\"\n",
    "\n",
    "formatted_preds = np.stack((uncal_predictions[exposure_col], uncal_predictions[outcome_col]))\n",
    "n_features, n_seqs, n_reps, n_variants = formatted_preds.shape\n",
    "formatted_preds = formatted_preds.transpose(2, 1, 3, 0)\n",
    "formatted_preds = formatted_preds.reshape(n_reps, n_seqs, 4, -1, n_features)\n",
    "\n",
    "unc_means, unc_mean_diffs, unc_stderrs = compute_summary_statistics(formatted_preds, np.array(sample_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_stderrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(unc_stderrs[:, :, :, 0].flatten(), stderrs[:, :, :, 0].flatten(), alpha = 0.05)\n",
    "sns.scatterplot(unc_stderrs[:, :, :, 1].flatten(), stderrs[:, :, :, 1].flatten(), alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_fpath, diffs, stderrs, x_col=0, y_col=1, sig_idxs=None):\n",
    "    fieldnames = [\n",
    "        \"seq_num\",\n",
    "        \"X_pred_mean\",\n",
    "        \"X_pred_var\",\n",
    "        \"Y_pred_mean\",\n",
    "        \"Y_pred_var\",\n",
    "    ]\n",
    "    if sig_idxs is None:\n",
    "        sig_idxs = np.full(diffs.shape, True, dtype=bool)\n",
    "    \n",
    "    with open(result_fpath, \"w\", newline=\"\") as out_file:\n",
    "        writer = csv.DictWriter(out_file, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        n_seqs, n_muts, seq_len, _ = diffs.shape\n",
    "        for seq_idx in range(n_seqs):\n",
    "            for seq_pos in range(seq_len):\n",
    "                for nt_pos in range(n_muts):\n",
    "                    if sig_idxs[seq_idx, nt_pos, seq_pos]:\n",
    "                        x_eff_size = diffs[seq_idx, nt_pos, seq_pos, x_col]\n",
    "                        y_eff_size = diffs[seq_idx, nt_pos, seq_pos, y_col]\n",
    "                        x_stderr = stderrs[seq_idx, nt_pos, seq_pos, x_col]\n",
    "                        y_stderr = stderrs[seq_idx, nt_pos, seq_pos, y_col]\n",
    "                        writer.writerow(\n",
    "                            {\n",
    "                                \"seq_num\": seq_idx + 1,\n",
    "                                \"X_pred_mean\": x_eff_size,\n",
    "                                \"X_pred_var\": x_stderr,\n",
    "                                \"Y_pred_mean\": y_eff_size,\n",
    "                                \"Y_pred_var\": y_stderr,\n",
    "                            }\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_instrument_candidates import filter_variants_by_score\n",
    "sig_var_idxs = filter_variants_by_score(mean_diffs[:, :, :, 0])\n",
    "print(\n",
    "    \"Reduced number of instruments down from %d to %d (%.2f %%)\" % \n",
    "    (np.prod(mean_diffs.shape), len(np.nonzero(sig_var_idxs)[0]), \n",
    "     float(len(np.nonzero(sig_var_idxs)[0]) / np.prod(mean_diffs.shape)) * 100)\n",
    ")\n",
    "print(sig_var_idxs.shape)\n",
    "results_fname = f'GATA_TAL1_effect_sizes_calibrated_v2.csv'\n",
    "results_fpath = os.path.join(mutagenesis_results_dir, results_fname)\n",
    "write_results(results_fpath, mean_diffs, stderrs, sig_idxs = sig_var_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_results = []\n",
    "for i in trange(len(sample_seqs)):\n",
    "    if mean_diffs[i, sig_var_idxs[i, :, :], 0].shape[0] > 0:\n",
    "        x = sm.add_constant(mean_diffs[i, sig_var_idxs[i, :, :], 0].flatten(), prepend=False)\n",
    "        y = mean_diffs[i, sig_var_idxs[i, :, :], 1].flatten()\n",
    "        ols_res = sm.OLS(y, x).fit()\n",
    "        ols_results.append(ols_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cis = [r.params[0] for r in ols_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
