{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import simdna\n",
    "from simdna import synthetic\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import one_hot_decode\n",
    "from in_silico_mutagenesis import compute_summary_statistics, generate_wt_mut_batches, write_results\n",
    "from pyx.one_hot import one_hot\n",
    "from tf_coop_model import CountsRegressor, IterablePandasDataset\n",
    "from tf_coop_model import anscombe_transform, run_one_epoch, spearman_rho, pearson_r\n",
    "from tf_coop_simulation import background_frequency\n",
    "from tf_coop_simulation import simulate_counts, simulate_oracle_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model & Load Weights\n",
    "This step assumes we've trained a counts regression model and have its weights stored in a .pt[h] file somewhere accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 3\n",
    "n_dense_layers = 3\n",
    "n_outputs = 2\n",
    "sequence_length = 100\n",
    "filters = 15\n",
    "filter_width = 7\n",
    "dense_layer_width = 30\n",
    "\n",
    "weights_dir = '../dat/sim/'\n",
    "weights_fname = 'cnn_counts_predictor.pt'\n",
    "test_data_fpath = '../dat/sim/test_labels.csv'\n",
    "raw_simulation_data_fpath = '../dat/sim/test_sequences.simdata'\n",
    "\n",
    "sequences_col = \"sequences\"\n",
    "label_cols = [\"labels_exp\", \"labels_out\"]\n",
    "batch_size = 1000\n",
    "n_samples = 10\n",
    "\n",
    "exposure_motif = \"GATA_disc1\"\n",
    "outcome_motif = \"TAL1_known1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7538570128>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, model_base_dir, model_fname, model_params, n_reps=5):\n",
    "        models = []\n",
    "        for i in range(1, n_reps+1):\n",
    "            model = CountsRegressor(**params)\n",
    "            model.load_state_dict(torch.load(os.path.join(model_base_dir, str(i), model_fname)))\n",
    "            models.append(model)\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, seqs, targets=None):\n",
    "        preds = {}\n",
    "        for model in self.models:\n",
    "            model_preds = model(seqs, targets=targets)\n",
    "            for key, preds_ in model_preds.items():\n",
    "                preds.setdefault(key, []).append(preds_.detach().cpu().numpy())\n",
    "        return {k: np.stack(v) for k, v in preds.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Ensemble at 0x7f751b250860>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_conv_layers\": n_conv_layers,\n",
    "    \"n_dense_layers\": n_dense_layers,\n",
    "    \"n_outputs\": n_outputs,\n",
    "    \"sequence_length\": sequence_length,\n",
    "    \"filters\": filters,\n",
    "    \"filter_width\": filter_width,\n",
    "    \"dense_layer_width\": dense_layer_width\n",
    "}\n",
    "ensemble_model = Ensemble(weights_dir, \"cnn_counts_predictor.pt\", params)\n",
    "ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data & Generate Predictions\n",
    "Now we're going to load test data to get some basic metrics about how well our model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_fpath)\n",
    "test_dataset = IterablePandasDataset(\n",
    "    test_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Deep MR\n",
    "So we see that the model predicts both sets of outputs quite well. Now, we want to understand whether the models capture the _interaction effects_ as defined by Finkelstein and Shrikumar et al.\n",
    "\n",
    "Finkelstein et al define an interaction effect as follows. Let $ s_{GT} $ denote a sequence containing strong matches for both motifs of interest (in our case, the GATA and TAL1 motifs). Then, let $ s_{T} $ denote the result of knocking out the GATA motif from $ s_{GT} $, and $ s_{G} $ the analogous result but for the TAL1 motif. Finally, let $ s_{\\emptyset} $ denote the result of knocking out both motifs. Denoting our model as $ f $, the TAL1 motif's per-sequence main effect contribution $ M_T $ is $ f(s_{GT}) - f(s_{G}) $ and GATA's $ M_G $ is $ f(s_{GT}) - f(s_{T}). $ The joint effect contribution is $ J_{G, T} = f(s_{GT}) - f(s_{\\emptyset}). $ The interaction effect $ I_{G, T} = J_{G, T} - (M_{G} + M_{T}). $\n",
    "\n",
    "In Shrikumar et al, all effects are computed in raw counts space. Here, for purposes of making our result relevant to Deep MR, we compute interaction effects in both Anscombe-transformed space and raw counts space but focus on the validity of the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_simulation_df = pd.read_csv(raw_simulation_data_fpath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_data_df = original_simulation_df.merge(test_df, left_on=\"sequence\", right_on=\"sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_df = merged_data_df[(merged_data_df['has_exposure'] == 1) & (merged_data_df['has_outcome'] == 1)]\n",
    "exposure_motif_df = merged_data_df[merged_data_df['has_exposure'] == 1]\n",
    "outcome_motif_df = merged_data_df[merged_data_df['has_outcome'] == 1]\n",
    "neither_motif_df = merged_data_df[\n",
    "    (merged_data_df['has_exposure'] == 0) & (merged_data_df['has_outcome'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488, 5029, 4990, 2469)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_motifs_df), len(exposure_motif_df), len(outcome_motif_df), len(neither_motif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts = list(background_frequency.keys())\n",
    "background_probs = list(background_frequency.values())\n",
    "\n",
    "def knock_out_motifs(sequence, knock_out_targets):\n",
    "    knocked_out_sequence = sequence\n",
    "    for knock_out_target in knock_out_targets:\n",
    "        replacement_sequence = np.random.choice(\n",
    "            nts, p=background_probs, size=len(knock_out_target[\"motif_string\"])\n",
    "        )\n",
    "        replacement_sequence = \"\".join(replacement_sequence)\n",
    "        knock_out_start = knock_out_target[\"start_position\"]\n",
    "        knock_out_end = knock_out_start + len(knock_out_target[\"motif_string\"])\n",
    "        knocked_out_sequence = (\n",
    "            knocked_out_sequence[:knock_out_start] +\n",
    "            replacement_sequence +\n",
    "            knocked_out_sequence[knock_out_end:]\n",
    "        )\n",
    "    \n",
    "    assert len(knocked_out_sequence) == len(sequence), (len(knocked_out_sequence), len(sequence))\n",
    "    return knocked_out_sequence\n",
    "\n",
    "def generate_knocked_out_sequences(sequences_df, exposure_name=\"GATA\", outcome_name=\"TAL1\"):\n",
    "    exposure_knock_outs = []\n",
    "    outcome_knock_outs = []\n",
    "    both_knock_outs = []\n",
    "    for row in sequences_df.iterrows():\n",
    "        sequence = row[1]['sequence']\n",
    "        embedding_info = [embedding.split(\"_\") for embedding in row[1][\"embeddings\"].split(\",\")]\n",
    "        knock_out_targets = {}\n",
    "        for embedding in embedding_info:\n",
    "            knock_out_target = {}\n",
    "            knock_out_target[\"start_position\"] = int(embedding[0].split(\"-\")[1]) # format 'pos-<start position>'\n",
    "            knock_out_target[\"motif_type\"] = embedding[1]\n",
    "            knock_out_target[\"motif_string\"] = embedding[2].split(\"-\")[1] # format '<motif name>-<string>'\n",
    "            assert embedding[1] in (exposure_name, outcome_name)\n",
    "            knock_out_targets[embedding[1]] = knock_out_target\n",
    "            \n",
    "        assert len(knock_out_targets) == 2, len(knock_out_targets) \n",
    "\n",
    "        exposure_knock_outs.append(knock_out_motifs(sequence, [knock_out_targets[exposure_name]]))\n",
    "        outcome_knock_outs.append(knock_out_motifs(sequence, [knock_out_targets[outcome_name]]))\n",
    "        both_knock_outs.append(knock_out_motifs(sequence, knock_out_targets.values()))\n",
    "    return exposure_knock_outs, outcome_knock_outs, both_knock_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_knock_outs, outcome_knock_outs, both_knock_outs = generate_knocked_out_sequences(both_motifs_df)\n",
    "both_motifs_df['sequence_exp_knock_out'] = exposure_knock_outs\n",
    "both_motifs_df['sequence_out_knock_out'] = outcome_knock_outs\n",
    "both_motifs_df['sequence_both_knock_out'] = both_knock_outs\n",
    "clear_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_dataset = IterablePandasDataset(\n",
    "    both_motifs_df, x_cols=sequences_col, y_cols=label_cols, x_transform=one_hot,\n",
    ")\n",
    "both_motifs_data_loader = torch.utils.data.DataLoader(\n",
    "    both_motifs_dataset, batch_size=batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutate_and_predict(model, sample_dataset):\n",
    "    preds = {}\n",
    "    all_muts = []\n",
    "    for seq, label in tqdm(sample_dataset):\n",
    "        muts = generate_wt_mut_batches(seq, seq.shape[0] * seq.shape[1]).squeeze()\n",
    "        muts = muts.transpose(0, 1, 2)\n",
    "        muts = torch.from_numpy(muts)\n",
    "        label = torch.from_numpy(label)\n",
    "        preds_ = model.predict(muts, targets=label)['predictions']\n",
    "        exposure_preds = preds_[:, :, 0]\n",
    "        outcome_preds = preds_[:, :, 1]\n",
    "        preds.setdefault('exposure', []).append(exposure_preds)\n",
    "        preds.setdefault('outcome', []).append(outcome_preds)\n",
    "        all_muts.append(muts.detach().cpu().numpy())\n",
    "    return all_muts, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_motifs_sample_dataset, _ = torch.utils.data.random_split(\n",
    "    both_motifs_dataset, (n_samples, len(both_motifs_dataset) - n_samples)\n",
    ")\n",
    "both_motifs_sample_seqs = [x for x, y in both_motifs_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d67202a93644bb7b3a46ce30785cd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/anaconda3/envs/deepmr/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([400, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "muts, preds = mutate_and_predict(ensemble_model, both_motifs_sample_dataset)\n",
    "sample_seqs = [seq for seq, label in both_motifs_sample_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1223b09e23e644fcb97c06492f657b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephenmalina/dev/an1lam/deepmr/src/in_silico_mutagenesis.py:168: RuntimeWarning: invalid value encountered in sqrt\n",
      "  stderrs = np.sqrt(ref_vars + mut_vars - 2 * covs)\n"
     ]
    }
   ],
   "source": [
    "exposure_col = \"exposure\"\n",
    "outcome_col = \"outcome\"\n",
    "\n",
    "formatted_preds = np.stack((preds[exposure_col], preds[outcome_col]))\n",
    "n_features, n_seqs, n_reps, n_variants = formatted_preds.shape\n",
    "formatted_preds = formatted_preds.transpose(2, 1, 3, 0)\n",
    "formatted_preds = formatted_preds.reshape(n_reps, n_seqs, 4, -1, n_features)\n",
    "\n",
    "means, mean_diffs, stderrs = compute_summary_statistics(formatted_preds, np.array(sample_seqs))\n",
    "\n",
    "# results_fname = f'GATA_TAL1_effect_sizes.csv'\n",
    "# results_fpath = os.path.join('../dat/sim', results_fname)\n",
    "# write_results(results_fpath, mean_diffs, stderrs)\n",
    "# print(results_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642025297808766\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.cla()\n",
    "seq_idxs = np.array(sample_seqs).astype(np.bool)\n",
    "mut_means = means[~seq_idxs].reshape(n_seqs, 3, 100, -1)\n",
    "x = (mut_means[5, :, :, 0]).flatten()\n",
    "y = (mut_means[5, :, :, 1]).flatten()\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, m*x + b)\n",
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepmr)",
   "language": "python",
   "name": "deepmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
